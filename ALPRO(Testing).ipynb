{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398715,"status":"ok","timestamp":1655772319032,"user":{"displayName":"Shuhong YE","userId":"01941125533231427731"},"user_tz":-480},"id":"8HlfhEK-ScMf","outputId":"47c94f85-850b-45d6-a8fd-acbf11010342"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting horovod[pytorch]\n","  Downloading horovod-0.24.3.tar.gz (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 15.6 MB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from horovod[pytorch]) (1.3.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from horovod[pytorch]) (5.4.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from horovod[pytorch]) (3.13)\n","Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from horovod[pytorch]) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from horovod[pytorch]) (1.11.0+cu113)\n","Collecting pytorch_lightning==1.3.8\n","  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\n","\u001b[K     |████████████████████████████████| 813 kB 59.6 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.0\n","  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.3.8->horovod[pytorch]) (2.8.0)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.3.8->horovod[pytorch]) (21.3)\n","Collecting pyyaml\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 105.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.3.8->horovod[pytorch]) (1.21.6)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 58.5 MB/s \n","\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 95.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.3.8->horovod[pytorch]) (4.64.0)\n","Collecting torchmetrics>=0.2.0\n","  Downloading torchmetrics-0.9.1-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 104.1 MB/s \n","\u001b[?25hRequirement already satisfied: pillow!=8.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.3.8->horovod[pytorch]) (7.1.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.4.0->horovod[pytorch]) (2.21)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.3.8->horovod[pytorch]) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 86.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning==1.3.8->horovod[pytorch]) (3.0.9)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (0.4.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (1.46.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (3.3.7)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (0.37.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (3.17.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (57.4.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (1.1.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (4.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.3.8->horovod[pytorch]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.3.8->horovod[pytorch]) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.3.8->horovod[pytorch]) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.3.8->horovod[pytorch]) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.3.8->horovod[pytorch]) (3.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 66.5 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.3.8->horovod[pytorch]) (21.4.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 82.3 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning==1.3.8->horovod[pytorch]) (2.0.12)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 82.0 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Building wheels for collected packages: horovod, future\n","  Building wheel for horovod (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for horovod: filename=horovod-0.24.3-cp37-cp37m-linux_x86_64.whl size=241084995 sha256=7cfc6f8ca52a101100d91b01d65fbd49d5b082c6e656c980cec5188b9330e3b3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3n6vxhgy/wheels/91/59/2a/27d91b72571213a3db5a15331ef4d40d979d2cde90ee629a14\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=7c518e8fac8dbb9c7349e6bf801ec4402e434f011e178832f11398347fb8ecd7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-3n6vxhgy/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built horovod future\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, pyyaml, pyDeprecate, future, pytorch-lightning, horovod\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 future-0.18.2 horovod-0.24.3 multidict-6.0.2 pyDeprecate-0.3.0 pytorch-lightning-1.3.8 pyyaml-5.4.1 torchmetrics-0.9.1 yarl-1.7.2\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,521 kB]\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,861 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,006 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,040 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,294 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,297 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n","Fetched 12.3 MB in 2s (6,124 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","49 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","lsof is already the newest version (4.89+dfsg-0.1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n","Found existing installation: Pillow 7.1.2\n","Uninstalling Pillow-7.1.2:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/PIL/*\n","    /usr/local/lib/python3.7/dist-packages/Pillow-7.1.2.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libfreetype-69f25d5e.so.6.17.1\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libjpeg-ba7bf5af.so.9.4.0\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/liblcms2-a6801db4.so.2.0.8\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/liblzma-99449165.so.5.2.5\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libopenjp2-b3d7668a.so.2.3.1\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libpng16-bedcb7ea.so.16.37.0\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libtiff-41910f6d.so.5.5.0\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libwebp-122bd20b.so.7.1.0\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libwebpdemux-2db559e5.so.2.0.6\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libwebpmux-ec1d5c76.so.3.0.5\n","    /usr/local/lib/python3.7/dist-packages/Pillow.libs/libz-a147dcb0.so.1.2.3\n","Proceed (y/n)? y\n","  Successfully uninstalled Pillow-7.1.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pillow-simd\n","  Downloading Pillow-SIMD-9.0.0.post1.tar.gz (849 kB)\n","\u001b[K     |████████████████████████████████| 849 kB 15.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pillow-simd\n","  Building wheel for pillow-simd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pillow-simd: filename=Pillow_SIMD-9.0.0.post1-cp37-cp37m-linux_x86_64.whl size=1255585 sha256=51fd23b634518f1fc9f4ee0c84db989821fd8947a4f76400abbafb8fa9d30459\n","  Stored in directory: /root/.cache/pip/wheels/9b/3f/fd/ca7133b4f7f509eb1de652bb8c128529a0c04b25ef0a6c535a\n","Successfully built pillow-simd\n","Installing collected packages: pillow-simd\n","Successfully installed pillow-simd-9.0.0.post1\n","\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n","full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-sm==3.3.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 15.1 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (57.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.23.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ipdb\n","  Downloading ipdb-0.13.9.tar.gz (16 kB)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.1.0)\n","Collecting cytoolz\n","  Downloading cytoolz-0.11.2.tar.gz (481 kB)\n","\u001b[K     |████████████████████████████████| 481 kB 14.3 MB/s \n","\u001b[?25hCollecting lz4==2.1.9\n","  Downloading lz4-2.1.9-cp37-cp37m-manylinux1_x86_64.whl (387 kB)\n","\u001b[K     |████████████████████████████████| 387 kB 84.9 MB/s \n","\u001b[?25hCollecting lmdb==0.97\n","  Downloading lmdb-0.97.tar.gz (869 kB)\n","\u001b[K     |████████████████████████████████| 869 kB 80.3 MB/s \n","\u001b[?25hCollecting msgpack-numpy\n","  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.0.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.11.2)\n","Collecting transformers==4.11.3\n","  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 56.9 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.64.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.9)\n","Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.0.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.1.2.30)\n","Collecting tensorboardX==2.0\n","  Downloading tensorboardX-2.0-py2.py3-none-any.whl (195 kB)\n","\u001b[K     |████████████████████████████████| 195 kB 83.8 MB/s \n","\u001b[?25hCollecting av==8.0.2\n","  Downloading av-8.0.2-cp37-cp37m-manylinux2010_x86_64.whl (36.9 MB)\n","\u001b[K     |████████████████████████████████| 36.9 MB 1.3 MB/s \n","\u001b[?25hCollecting ujson\n","  Downloading ujson-5.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 3.6 MB/s \n","\u001b[?25hCollecting einops\n","  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n","Collecting decord\n","  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","\u001b[K     |████████████████████████████████| 13.6 MB 73.8 MB/s \n","\u001b[?25hCollecting timm\n","  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n","\u001b[K     |████████████████████████████████| 431 kB 92.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (4.11.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 64.7 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.17\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (1.21.6)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 76.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (5.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (21.3)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.0->-r requirements.txt (line 15)) (3.17.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.0->-r requirements.txt (line 15)) (1.15.0)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.1->-r requirements.txt (line 13)) (3.2.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.3->-r requirements.txt (line 9)) (4.1.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->-r requirements.txt (line 13)) (1.4.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->-r requirements.txt (line 13)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->-r requirements.txt (line 13)) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->-r requirements.txt (line 13)) (2.8.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb->-r requirements.txt (line 1)) (57.4.0)\n","Collecting ipython>=7.17.0\n","  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 81.4 MB/s \n","\u001b[?25hCollecting toml>=0.10.2\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipdb->-r requirements.txt (line 1)) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (2.6.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (4.8.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (0.18.1)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n","\u001b[K     |████████████████████████████████| 381 kB 81.0 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (0.1.3)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb->-r requirements.txt (line 1)) (0.2.5)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.3.7)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.35.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.37.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.8.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.46.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 10)) (1.3.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.11.3->-r requirements.txt (line 9)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 10)) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.3->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.3->-r requirements.txt (line 9)) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.3->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.3->-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 10)) (3.2.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm->-r requirements.txt (line 20)) (0.12.0+cu113)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm->-r requirements.txt (line 20)) (1.11.0+cu113)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.3->-r requirements.txt (line 9)) (7.1.2)\n","Collecting pillow!=8.3.*,>=5.3.0\n","  Downloading Pillow-9.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 81.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: lmdb, ipdb, cytoolz, sacremoses\n","  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lmdb: filename=lmdb-0.97-cp37-cp37m-linux_x86_64.whl size=219817 sha256=3989963d13cc8208c75ff74edda797a1d087ed83ebd8d1b3eb2057722c40ac2b\n","  Stored in directory: /root/.cache/pip/wheels/fc/9c/16/01d282ed6747f9eed531b21539e1e5e6be4adf093e2e2db7a6\n","  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ipdb: filename=ipdb-0.13.9-py3-none-any.whl size=11648 sha256=56707f7e969b21e30303861d6c6f9233dca79fe5842b32cd6e6083f97e58b1ca\n","  Stored in directory: /root/.cache/pip/wheels/65/cd/cc/aaf92acae337a28fdd2aa4d632196a59745c8c39f76eaeed01\n","  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cytoolz: filename=cytoolz-0.11.2-cp37-cp37m-linux_x86_64.whl size=1236738 sha256=73590c5612bb769a8c3cf5ec225799df94f8c0ee77627252822393f03d41a584\n","  Stored in directory: /root/.cache/pip/wheels/38/70/71/ca13ea3d36ccd0b3d0ec7d7a4ca67522048d695b556bba4f59\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=3b08e32354d5597049f209e3ef7cfe5ad997dc3b315fd0d0afbb314f7e700811\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built lmdb ipdb cytoolz sacremoses\n","Installing collected packages: prompt-toolkit, pillow, toml, tokenizers, sacremoses, ipython, huggingface-hub, ujson, transformers, timm, tensorboardX, msgpack-numpy, lz4, lmdb, ipdb, einops, decord, cytoolz, av\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Attempting uninstall: lmdb\n","    Found existing installation: lmdb 0.99\n","    Uninstalling lmdb-0.99:\n","      Successfully uninstalled lmdb-0.99\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed av-8.0.2 cytoolz-0.11.2 decord-0.6.0 einops-0.4.1 huggingface-hub-0.7.0 ipdb-0.13.9 ipython-7.34.0 lmdb-0.97 lz4-2.1.9 msgpack-numpy-0.4.8 pillow-9.1.1 prompt-toolkit-3.0.29 sacremoses-0.0.53 tensorboardX-2.0 timm-0.5.4 tokenizers-0.10.3 toml-0.10.2 transformers-4.11.3 ujson-5.3.0\n","\n","\n","torch.__version__  = 1.11.0+cu113\n","\n","\n","setup.py:121: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","  warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","running install\n","running bdist_egg\n","running egg_info\n","writing apex.egg-info/PKG-INFO\n","writing dependency_links to apex.egg-info/dependency_links.txt\n","writing top-level names to apex.egg-info/top_level.txt\n","adding license file 'LICENSE'\n","writing manifest file 'apex.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/apex\n","copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n","copying build/lib/apex/_autocast_utils.py -> build/bdist.linux-x86_64/egg/apex\n","creating build/bdist.linux-x86_64/egg/apex/RNN\n","copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n","copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n","copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n","copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n","creating build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n","copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n","creating build/bdist.linux-x86_64/egg/apex/amp/lists\n","copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n","copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n","copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n","copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n","creating build/bdist.linux-x86_64/egg/apex/contrib\n","copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib\n","creating build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/bottleneck_module_test.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n","creating build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n","copying build/lib/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n","copying build/lib/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu\n","creating build/bdist.linux-x86_64/egg/apex/contrib/fmha\n","copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n","copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n","creating build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n","copying build/lib/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n","copying build/lib/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/egg/apex/contrib/focal_loss\n","creating build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n","copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n","copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n","creating build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n","copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n","copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n","creating build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n","creating build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n","creating build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","copying build/lib/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","copying build/lib/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","copying build/lib/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","copying build/lib/apex/contrib/peer_memory/peer_halo_exchange_module_tests.py -> build/bdist.linux-x86_64/egg/apex/contrib/peer_memory\n","creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","copying build/lib/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n","creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","copying build/lib/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels\n","creating build/bdist.linux-x86_64/egg/apex/contrib/transducer\n","copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n","copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n","creating build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n","copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n","copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n","creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n","copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n","copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n","copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n","copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n","creating build/bdist.linux-x86_64/egg/apex/fused_dense\n","copying build/lib/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/egg/apex/fused_dense\n","copying build/lib/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/egg/apex/fused_dense\n","creating build/bdist.linux-x86_64/egg/apex/mlp\n","copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/egg/apex/mlp\n","copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/egg/apex/mlp\n","creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n","copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n","copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n","creating build/bdist.linux-x86_64/egg/apex/normalization\n","copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n","copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n","creating build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n","creating build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n","creating build/bdist.linux-x86_64/egg/apex/pyprof\n","copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof\n","creating build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n","copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n","copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n","creating build/bdist.linux-x86_64/egg/apex/pyprof/parse\n","copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n","copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n","copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n","copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n","copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n","copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n","creating build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n","creating build/bdist.linux-x86_64/egg/apex/reparameterization\n","copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n","copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n","copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n","creating build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/log_util.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","copying build/lib/apex/transformer/enums.py -> build/bdist.linux-x86_64/egg/apex/transformer\n","creating build/bdist.linux-x86_64/egg/apex/transformer/_data\n","copying build/lib/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/egg/apex/transformer/_data\n","copying build/lib/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/_data\n","creating build/bdist.linux-x86_64/egg/apex/transformer/amp\n","copying build/lib/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/egg/apex/transformer/amp\n","copying build/lib/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/amp\n","creating build/bdist.linux-x86_64/egg/apex/transformer/functional\n","copying build/lib/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/egg/apex/transformer/functional\n","copying build/lib/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/functional\n","creating build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","copying build/lib/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","copying build/lib/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","copying build/lib/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","copying build/lib/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel\n","creating build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules\n","creating build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","copying build/lib/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel\n","creating build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","copying build/lib/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/egg/apex/transformer/testing\n","byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/_autocast_utils.py to _autocast_utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/halo_exchangers.py to halo_exchangers.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/bottleneck_module_test.py to bottleneck_module_test.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/test.py to test.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu/conv_bias_relu.py to conv_bias_relu.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/conv_bias_relu/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/fmha.py to fmha.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/focal_loss/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/focal_loss/focal_loss.py to focal_loss.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_halo_exchanger_1d.py to peer_halo_exchanger_1d.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_memory.py to peer_memory.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/peer_memory/peer_halo_exchange_module_tests.py to peer_halo_exchange_module_tests.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_lib.py to permutation_lib.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/asp.py to asp.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py to call_permutation_search_kernels.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py to exhaustive_search.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py to permutation_utilities.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/transducer.py to transducer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fused_dense/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/fused_dense/fused_dense.py to fused_dense.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/mlp.py to mlp.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_mixed_precision_lamb.py to fused_mixed_precision_lamb.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_novograd.py to fused_novograd.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/parse.py to parse.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__main__.py to __main__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/kernel.py to kernel.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/nvvp.py to nvvp.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/db.py to db.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/dropout.py to dropout.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/randomSample.py to randomSample.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/misc.py to misc.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/usage.py to usage.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/loss.py to loss.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/utility.py to utility.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/softmax.py to softmax.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/linear.py to linear.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__main__.py to __main__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/activation.py to activation.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/data.py to data.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/prof.py to prof.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/embedding.py to embedding.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pointwise.py to pointwise.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/output.py to output.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/conv.py to conv.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/blas.py to blas.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/optim.py to optim.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/reduction.py to reduction.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pooling.py to pooling.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/normalization.py to normalization.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/base.py to base.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/convert.py to convert.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/reparameterization.py to reparameterization.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/weight_norm.py to weight_norm.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/microbatches.py to microbatches.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/log_util.py to log_util.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/parallel_state.py to parallel_state.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/enums.py to enums.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_data/_batchsampler.py to _batchsampler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/_data/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/amp/grad_scaler.py to grad_scaler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/amp/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/functional/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/p2p_communication.py to p2p_communication.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/_timers.py to _timers.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/common.py to common.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py to fwd_bwd_pipelining_with_interleaving.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py to fwd_bwd_no_pipelining.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py to fwd_bwd_pipelining_without_interleaving.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/data.py to data.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/memory.py to memory.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/random.py to random.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/utils.py to utils.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/layers.py to layers.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_bert.py to standalone_bert.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/distributed_test_base.py to distributed_test_base.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/arguments.py to arguments.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/global_vars.py to global_vars.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/commons.py to commons.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/apex/transformer/testing/standalone_gpt.py to standalone_gpt.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","apex.pyprof.nvtx.__pycache__.nvmarker.cpython-37: module references __file__\n","apex.pyprof.nvtx.__pycache__.nvmarker.cpython-37: module references __path__\n","creating 'dist/apex-0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing apex-0.1-py3.7.egg\n","creating /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7.egg\n","Extracting apex-0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","Adding apex 0.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7.egg\n","Processing dependencies for apex==0.1\n","Finished processing dependencies for apex==0.1\n"]}],"source":["import os\n","os.chdir('/content/drive/MyDrive/Colab projects/VideoQA research projects/ALPRO(Testing)/ALPRO-main/env')\n","# horovod HOROVOD_NCCL_LINK=STATIC | SHARED\n","!HOROVOD_GPU_ALLREDUCE=NCCL  HOROVOD_WITH_PYTORCH=1 pip install --no-cache-dir horovod[pytorch] && ldconfig\n","!bash install_pkg.sh\n","#git clone https://github.com/NVIDIA/apex.git &&\\\n","!cd apex &&\\\n","    python setup.py install &&\\\n","    rm -rf ../apex#"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6373,"status":"ok","timestamp":1655684165494,"user":{"displayName":"Shuhong YE","userId":"01941125533231427731"},"user_tz":-480},"id":"m1_zo1wQ_oTr","outputId":"d8307c98-108f-4876-958a-6ea211b3c090"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.11.0+cu113\n","Mon Jun 20 00:16:00 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Num GPUs Available:  1\n"]}],"source":["!python -c \"import torch;print(torch.__version__)\"\n","!nvidia-smi\n","!python -c \"import tensorflow as tf;print(\\\"Num GPUs Available: \\\", len(tf.config.experimental.list_physical_devices('GPU')))\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KcNBy6Eio10O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655658920808,"user_tz":-480,"elapsed":30894486,"user":{"displayName":"Shuhong YE","userId":"01941125533231427731"}},"outputId":"32228be1-cdaa-43c0-e26a-21e05157291e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/env/python:/content/drive/MyDrive/Colab projects/VideoQA research projects/ALPRO(Testing)/ALPRO-main\n","Step:1500\n","[1,0]<stderr>:06/19/2022 08:40:34 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 08:40:34 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 08:40:34 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 08:40:34 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 08:40:40 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_1500.pt\n","[1,0]<stderr>:06/19/2022 08:40:46 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 08:40:46 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 08:40:47 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 08:40:47 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 08:40:47 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 08:40:47 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 08:40:47 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 08:40:47 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 08:40:47 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_1500.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '1500', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 08:40:51 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:11<00:00,  2.40s/it][1,0]<stderr>:06/19/2022 09:03:03 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1201, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 1415, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1201, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 09:03:03 - INFO - __main__ -   validation finished in 1331 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.49, 'what_acc': 33.56, 'who_acc': 60.72, 'how_acc': 80.27, 'where_acc': 53.57, 'when_acc': 74.14}\n","100%|██████████| 412/412 [22:11<00:00,  3.23s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 09:03:03 - INFO - __main__ -   all results written\n","Step:1800\n","[1,0]<stderr>:06/19/2022 09:03:11 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 09:03:11 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 09:03:11 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 09:03:11 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 09:03:17 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_1800.pt\n","[1,0]<stderr>:06/19/2022 09:03:22 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 09:03:22 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 09:03:23 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 09:03:23 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 09:03:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:03:23 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 09:03:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:03:23 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 09:03:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_1800.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '1800', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 09:03:28 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:16<00:00,  2.33s/it][1,0]<stderr>:06/19/2022 09:25:44 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1092, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 1415, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 2390, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 09:25:44 - INFO - __main__ -   validation finished in 1336 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 45.28, 'what_acc': 35.3, 'who_acc': 59.73, 'how_acc': 82.7, 'where_acc': 42.86, 'when_acc': 74.14}\n","100%|██████████| 412/412 [22:16<00:00,  3.24s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 09:25:44 - INFO - __main__ -   all results written\n","Step:2100\n","[1,0]<stderr>:06/19/2022 09:25:52 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 09:25:52 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 09:25:52 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 09:25:52 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 09:25:58 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_2100.pt\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 09:26:04 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_2100.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '2100', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 09:26:09 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:55<00:00,  2.33s/it][1,0]<stderr>:06/19/2022 09:48:04 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 230, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 2390, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 09:48:04 - INFO - __main__ -   validation finished in 1315 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 45.33, 'what_acc': 36.18, 'who_acc': 58.41, 'how_acc': 81.62, 'where_acc': 46.43, 'when_acc': 72.41}\n","100%|██████████| 412/412 [21:55<00:00,  3.19s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 09:48:04 - INFO - __main__ -   all results written\n","Step:2400\n","[1,0]<stderr>:06/19/2022 09:48:13 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 09:48:13 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 09:48:13 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 09:48:13 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 09:48:18 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_2400.pt\n","[1,0]<stderr>:06/19/2022 09:48:19 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 09:48:19 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 09:48:20 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 09:48:20 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 09:48:20 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:48:20 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 09:48:20 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:48:20 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 09:48:20 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_2400.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '2400', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 09:48:24 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:01<00:00,  2.35s/it][1,0]<stderr>:06/19/2022 10:10:25 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1201, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 230, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 10:10:25 - INFO - __main__ -   validation finished in 1321 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.74, 'what_acc': 35.73, 'who_acc': 57.82, 'how_acc': 77.84, 'where_acc': 42.86, 'when_acc': 72.41}\n","100%|██████████| 412/412 [22:01<00:00,  3.21s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 10:10:26 - INFO - __main__ -   all results written\n","Step:2700\n","[1,0]<stderr>:06/19/2022 10:10:34 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 10:10:34 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 10:10:34 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 10:10:34 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 10:10:40 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_2700.pt\n","[1,0]<stderr>:06/19/2022 10:10:45 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 10:10:45 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 10:10:46 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 10:10:46 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 10:10:46 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:10:46 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 10:10:46 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:10:46 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 10:10:46 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_2700.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '2700', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 10:10:50 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:57<00:00,  2.32s/it][1,0]<stderr>:06/19/2022 10:32:48 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 10:32:48 - INFO - __main__ -   validation finished in 1317 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.48, 'what_acc': 35.22, 'who_acc': 57.64, 'how_acc': 81.35, 'where_acc': 50.0, 'when_acc': 74.14}\n","100%|██████████| 412/412 [21:57<00:00,  3.20s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 10:32:48 - INFO - __main__ -   all results written\n","Step:3000\n","[1,0]<stderr>:06/19/2022 10:32:56 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 10:32:56 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 10:32:56 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 10:32:56 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 10:33:02 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_3000.pt\n","[1,0]<stderr>:06/19/2022 10:33:07 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 10:33:07 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 10:33:08 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 10:33:08 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 10:33:08 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:33:08 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 10:33:08 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:33:08 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 10:33:08 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_3000.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '3000', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 10:33:12 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:04<00:00,  2.32s/it][1,0]<stderr>:06/19/2022 10:55:17 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1201, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 1433, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 10:55:17 - INFO - __main__ -   validation finished in 1324 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 45.33, 'what_acc': 36.48, 'who_acc': 57.89, 'how_acc': 81.08, 'where_acc': 46.43, 'when_acc': 74.14}\n","100%|██████████| 412/412 [22:04<00:00,  3.22s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 10:55:17 - INFO - __main__ -   all results written\n","Step:3300\n","[1,0]<stderr>:06/19/2022 10:55:25 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 10:55:25 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 10:55:25 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 10:55:25 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 10:55:31 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_3300.pt\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 10:55:38 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_3300.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '3300', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 10:55:43 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:20<00:00,  2.32s/it][1,0]<stderr>:06/19/2022 11:18:03 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1201, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 230, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 11:18:03 - INFO - __main__ -   validation finished in 1340 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 45.28, 'what_acc': 36.1, 'who_acc': 58.33, 'how_acc': 81.89, 'where_acc': 53.57, 'when_acc': 74.14}\n","100%|██████████| 412/412 [22:20<00:00,  3.25s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 11:18:03 - INFO - __main__ -   all results written\n","Step:3600\n","[1,0]<stderr>:06/19/2022 11:18:11 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 11:18:11 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 11:18:11 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 11:18:11 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'bert.pooler.dense.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 11:18:17 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_3600.pt\n","[1,0]<stderr>:06/19/2022 11:18:22 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 11:18:22 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 11:18:23 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 11:18:23 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 11:18:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 11:18:23 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 11:18:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 11:18:23 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 11:18:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_3600.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '3600', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 11:18:27 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:19<00:00,  2.36s/it][1,0]<stderr>:06/19/2022 11:40:47 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 11:40:47 - INFO - __main__ -   validation finished in 1339 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.98, 'what_acc': 36.67, 'who_acc': 56.5, 'how_acc': 81.89, 'where_acc': 46.43, 'when_acc': 72.41}\n","100%|██████████| 412/412 [22:19<00:00,  3.25s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 11:40:48 - INFO - __main__ -   all results written\n","Step:3900\n","[1,0]<stderr>:06/19/2022 11:40:56 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 11:40:56 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 11:40:56 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 11:40:56 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 11:41:02 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_3900.pt\n","[1,0]<stderr>:06/19/2022 11:41:08 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 11:41:08 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 11:41:09 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 11:41:09 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 11:41:09 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 11:41:09 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 11:41:09 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 11:41:09 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 11:41:09 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_3900.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '3900', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 11:41:13 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:14<00:00,  2.36s/it][1,0]<stderr>:06/19/2022 12:03:28 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1201, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 12:03:28 - INFO - __main__ -   validation finished in 1334 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 45.85, 'what_acc': 36.92, 'who_acc': 58.79, 'how_acc': 78.92, 'where_acc': 50.0, 'when_acc': 72.41}\n","100%|██████████| 412/412 [22:14<00:00,  3.24s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 12:03:28 - INFO - __main__ -   all results written\n","Step:4200\n","[1,0]<stderr>:06/19/2022 12:03:36 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 12:03:36 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 12:03:36 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 12:03:36 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 12:03:42 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_4200.pt\n","[1,0]<stderr>:06/19/2022 12:03:47 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 12:03:47 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 12:03:48 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 12:03:48 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 12:03:48 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:03:48 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 12:03:48 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:03:48 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 12:03:48 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:03:52 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_4200.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '4200', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 12:03:53 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:09<00:00,  2.40s/it][1,0]<stderr>:06/19/2022 12:26:02 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1201, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1201, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 12:26:02 - INFO - __main__ -   validation finished in 1329 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 45.6, 'what_acc': 36.34, 'who_acc': 59.18, 'how_acc': 78.11, 'where_acc': 50.0, 'when_acc': 72.41}\n","100%|██████████| 412/412 [22:09<00:00,  3.23s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 12:26:02 - INFO - __main__ -   all results written\n","Step:4500\n","[1,0]<stderr>:06/19/2022 12:26:10 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 12:26:10 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 12:26:10 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 12:26:10 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'bert.pooler.dense.bias', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 12:26:16 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_4500.pt\n","[1,0]<stderr>:06/19/2022 12:26:22 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 12:26:22 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 12:26:23 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 12:26:23 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 12:26:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:26:23 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 12:26:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:26:23 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 12:26:23 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_4500.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '4500', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 12:26:27 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:49<00:00,  2.32s/it][1,0]<stderr>:06/19/2022 12:48:17 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1201, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 12:48:17 - INFO - __main__ -   validation finished in 1309 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 45.15, 'what_acc': 36.37, 'who_acc': 57.47, 'how_acc': 82.16, 'where_acc': 50.0, 'when_acc': 72.41}\n","100%|██████████| 412/412 [21:49<00:00,  3.18s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 12:48:17 - INFO - __main__ -   all results written\n","Step:4800\n","[1,0]<stderr>:06/19/2022 12:48:25 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 12:48:25 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 12:48:25 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 12:48:25 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 12:48:31 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_4800.pt\n","[1,0]<stderr>:06/19/2022 12:48:36 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 12:48:36 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 12:48:37 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 12:48:37 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 12:48:37 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:48:37 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 12:48:37 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:48:37 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 12:48:37 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_4800.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '4800', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 12:48:41 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:56<00:00,  2.33s/it][1,0]<stderr>:06/19/2022 13:10:38 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1201, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1201, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 13:10:38 - INFO - __main__ -   validation finished in 1316 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.18, 'what_acc': 35.49, 'who_acc': 56.26, 'how_acc': 81.89, 'where_acc': 50.0, 'when_acc': 74.14}\n","100%|██████████| 412/412 [21:56<00:00,  3.20s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 13:10:38 - INFO - __main__ -   all results written\n","Step:5100\n","[1,0]<stderr>:06/19/2022 13:10:47 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 13:10:47 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 13:10:47 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 13:10:47 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 13:10:52 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_5100.pt\n","[1,0]<stderr>:06/19/2022 13:10:59 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 13:10:59 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 13:11:00 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 13:11:00 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 13:11:00 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:11:00 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 13:11:00 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:11:00 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 13:11:00 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_5100.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '5100', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 13:11:04 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:08<00:00,  2.31s/it][1,0]<stderr>:06/19/2022 13:33:12 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 13:33:12 - INFO - __main__ -   validation finished in 1328 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.82, 'what_acc': 36.75, 'who_acc': 55.8, 'how_acc': 82.97, 'where_acc': 46.43, 'when_acc': 72.41}\n","100%|██████████| 412/412 [22:08<00:00,  3.22s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 13:33:12 - INFO - __main__ -   all results written\n","Step:5400\n","[1,0]<stderr>:06/19/2022 13:33:21 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 13:33:21 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 13:33:21 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 13:33:21 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'cls.predictions.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 13:33:26 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_5400.pt\n","[1,0]<stderr>:06/19/2022 13:33:32 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 13:33:32 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 13:33:33 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 13:33:33 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 13:33:33 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:33:33 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 13:33:33 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:33:33 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 13:33:33 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_5400.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '5400', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 13:33:37 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:44<00:00,  2.33s/it][1,0]<stderr>:06/19/2022 13:55:22 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1201, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 13:55:22 - INFO - __main__ -   validation finished in 1304 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 45.41, 'what_acc': 36.53, 'who_acc': 57.97, 'how_acc': 81.62, 'where_acc': 46.43, 'when_acc': 74.14}\n","100%|██████████| 412/412 [21:44<00:00,  3.17s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 13:55:22 - INFO - __main__ -   all results written\n","Step:5700\n","[1,0]<stderr>:06/19/2022 13:55:31 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 13:55:31 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 13:55:31 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 13:55:31 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 13:55:36 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_5700.pt\n","[1,0]<stderr>:06/19/2022 13:55:42 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 13:55:42 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 13:55:43 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 13:55:43 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 13:55:43 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:55:43 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 13:55:43 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:55:43 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 13:55:43 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_5700.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '5700', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 13:55:47 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:36<00:00,  2.30s/it][1,0]<stderr>:06/19/2022 14:17:23 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 14:17:23 - INFO - __main__ -   validation finished in 1296 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.71, 'what_acc': 36.26, 'who_acc': 56.5, 'how_acc': 81.35, 'where_acc': 46.43, 'when_acc': 72.41}\n","100%|██████████| 412/412 [21:36<00:00,  3.15s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 14:17:23 - INFO - __main__ -   all results written\n","Step:6000\n","[1,0]<stderr>:06/19/2022 14:17:32 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 14:17:32 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 14:17:32 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 14:17:32 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 14:17:37 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_6000.pt\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 14:17:43 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_6000.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '6000', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 14:17:48 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:27<00:00,  2.34s/it][1,0]<stderr>:06/19/2022 14:39:15 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 14:39:15 - INFO - __main__ -   validation finished in 1287 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.74, 'what_acc': 36.5, 'who_acc': 56.11, 'how_acc': 81.62, 'where_acc': 46.43, 'when_acc': 74.14}\n","100%|██████████| 412/412 [21:27<00:00,  3.12s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 14:39:15 - INFO - __main__ -   all results written\n","Step:6300\n","[1,0]<stderr>:06/19/2022 14:39:24 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 14:39:24 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 14:39:24 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 14:39:24 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'bert.pooler.dense.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'bert.pooler.dense.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 14:39:30 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_6300.pt\n","[1,0]<stderr>:06/19/2022 14:39:35 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 14:39:35 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 14:39:36 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 14:39:36 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 14:39:36 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 14:39:36 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 14:39:36 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 14:39:36 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 14:39:36 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 14:39:40 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_6300.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '6300', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 14:39:41 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:47<00:00,  2.32s/it][1,0]<stderr>:06/19/2022 15:01:28 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 15:01:28 - INFO - __main__ -   validation finished in 1307 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.9, 'what_acc': 36.4, 'who_acc': 56.83, 'how_acc': 81.08, 'where_acc': 46.43, 'when_acc': 72.41}\n","100%|██████████| 412/412 [21:47<00:00,  3.17s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 15:01:28 - INFO - __main__ -   all results written\n","Step:6600\n","[1,0]<stderr>:06/19/2022 15:01:37 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 15:01:37 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 15:01:37 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 15:01:37 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'bert.pooler.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.weight', 'cls.predictions.transform.dense.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 15:01:43 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_6600.pt\n","[1,0]<stderr>:06/19/2022 15:01:48 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 15:01:48 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 15:01:49 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 15:01:49 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 15:01:49 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:01:49 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 15:01:49 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:01:49 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 15:01:49 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:01:53 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_6600.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '6600', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 15:01:54 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:51<00:00,  2.33s/it][1,0]<stderr>:06/19/2022 15:23:45 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 15:23:45 - INFO - __main__ -   validation finished in 1311 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.71, 'what_acc': 36.14, 'who_acc': 56.77, 'how_acc': 80.27, 'where_acc': 50.0, 'when_acc': 74.14}\n","100%|██████████| 412/412 [21:51<00:00,  3.18s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 15:23:45 - INFO - __main__ -   all results written\n","Step:6900\n","[1,0]<stderr>:06/19/2022 15:23:53 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 15:23:53 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 15:23:53 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 15:23:53 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.pooler.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.predictions.transform.dense.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 15:23:59 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_6900.pt\n","[1,0]<stderr>:06/19/2022 15:24:06 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 15:24:06 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 15:24:07 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 15:24:07 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 15:24:07 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:24:07 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 15:24:07 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:24:07 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 15:24:07 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_6900.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '6900', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 15:24:11 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [22:05<00:00,  2.32s/it][1,0]<stderr>:06/19/2022 15:46:16 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 15:46:16 - INFO - __main__ -   validation finished in 1325 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.84, 'what_acc': 36.15, 'who_acc': 57.07, 'how_acc': 80.81, 'where_acc': 46.43, 'when_acc': 74.14}\n","100%|██████████| 412/412 [22:05<00:00,  3.22s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 15:46:16 - INFO - __main__ -   all results written\n","Step:7200\n","[1,0]<stderr>:06/19/2022 15:46:25 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 15:46:25 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 15:46:25 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 15:46:25 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 15:46:31 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_7200.pt\n","[1,0]<stderr>:06/19/2022 15:46:37 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 15:46:37 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 15:46:38 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 15:46:38 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 15:46:38 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:46:38 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 15:46:38 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:46:38 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 15:46:38 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_7200.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '7200', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 15:46:42 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:51<00:00,  2.34s/it][1,0]<stderr>:06/19/2022 16:08:34 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 16:08:34 - INFO - __main__ -   validation finished in 1311 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.81, 'what_acc': 36.14, 'who_acc': 56.96, 'how_acc': 81.35, 'where_acc': 50.0, 'when_acc': 74.14}\n","100%|██████████| 412/412 [21:51<00:00,  3.18s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 16:08:34 - INFO - __main__ -   all results written\n","Step:7500\n","[1,0]<stderr>:06/19/2022 16:08:42 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 16:08:42 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 16:08:42 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 16:08:42 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'bert.pooler.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 16:08:48 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_7500.pt\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 16:08:56 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_7500.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '7500', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 16:09:01 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:51<00:00,  2.31s/it][1,0]<stderr>:06/19/2022 16:30:52 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 16:30:52 - INFO - __main__ -   validation finished in 1311 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.86, 'what_acc': 36.65, 'who_acc': 56.28, 'how_acc': 80.27, 'where_acc': 46.43, 'when_acc': 74.14}\n","100%|██████████| 412/412 [21:51<00:00,  3.18s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 16:30:52 - INFO - __main__ -   all results written\n","Step:7800\n","[1,0]<stderr>:06/19/2022 16:31:01 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 16:31:01 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 16:31:01 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 16:31:01 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 16:31:07 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_7800.pt\n","[1,0]<stderr>:06/19/2022 16:31:12 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 16:31:12 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 16:31:13 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 16:31:13 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 16:31:13 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:31:13 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 16:31:13 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:31:13 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 16:31:13 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_7800.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '7800', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 16:31:17 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:48<00:00,  2.32s/it][1,0]<stderr>:06/19/2022 16:53:05 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 16:53:05 - INFO - __main__ -   validation finished in 1308 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.76, 'what_acc': 36.25, 'who_acc': 56.63, 'how_acc': 80.81, 'where_acc': 50.0, 'when_acc': 75.86}\n","100%|██████████| 412/412 [21:48<00:00,  3.18s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 16:53:05 - INFO - __main__ -   all results written\n","Step:8100\n","[1,0]<stderr>:06/19/2022 16:53:14 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/19/2022 16:53:14 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/19/2022 16:53:14 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/19/2022 16:53:14 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/19/2022 16:53:20 - INFO - __main__ -   Loading e2e weights from output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_8100.pt\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   No temporal encoding found. Or the length of temporal position embedding matches. No need to resize.\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/19/2022 16:53:26 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   Loaded data size 13157\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   datalist 13157\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   grouped 504\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   group_datalist 13157\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   is_train False, dataset size 13157 groups, each group 1\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'output/downstreams/msvd_qa/private/20220616134649/log/model_config.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msvd_qa/private/20220616134649', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 30, 'min_valid_steps': 50, 'save_steps_ratio': 0.05, 'num_train_epochs': 15, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 20.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/downstreams/msvd_qa/private/20220616134649/ckpt/model_step_8100.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': '8100', 'do_inference': True, 'inference_split': 'test', 'inference_txt_db': 'data/msvd_qa/txt/test.jsonl', 'inference_img_db': 'data/msvd_qa/videos', 'inference_batch_size': 32, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msvd_qa.json', 'task': 'msvd_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msvd_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/train.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'val_datasets': [{'name': 'msvd_qa', 'txt': {'msvd_qa': 'data/msvd_qa/txt/val.jsonl'}, 'img': 'data/msvd_qa/videos'}], 'num_labels': 2423, 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'gradient_accumulation_steps_original': 2, 'cnn_lr_decay': 'linear', 'num_workers': 4}\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   Starting inference...\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   ***** Running inference with 1 GPUs *****\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -     Batch size = 32\n","[1,0]<stderr>:06/19/2022 16:53:31 - INFO - __main__ -   Step 0: start validation\n","100%|██████████| 412/412 [21:47<00:00,  2.33s/it][1,0]<stderr>:06/19/2022 17:15:19 - INFO - __main__ -   QA Task [msvd_qa], 13157 qa_results,3 examples here: [{'question_id': 0, 'answer': 1949, 'data': {'question': 'who opened the box that held an automatic weapon in a gun?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'someone', 'question_id': 0, 'answer_type': 'who'}}, {'question_id': 1, 'answer': 2345, 'data': {'question': 'what contains someone opens the lid of a corrugated cardboard?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'rifle', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 1467, 'data': {'question': 'who opens a box containing an assault rifle?', 'vid_id': 'jfrrO5K_vKM_55_65', 'answer': 'man', 'question_id': 2, 'answer_type': 'who'}}]\n","[1,0]<stderr>:06/19/2022 17:15:19 - INFO - __main__ -   validation finished in 1307 seconds.{'ratios': {'what_ratio': [61.94, 8149], 'who_ratio': [34.6, 4552], 'how_ratio': [2.81, 370], 'where_ratio': [0.21, 28], 'when_ratio': [0.44, 58]}, 'overall_acc': 44.87, 'what_acc': 36.52, 'who_acc': 56.5, 'how_acc': 80.54, 'where_acc': 50.0, 'when_acc': 74.14}\n","100%|██████████| 412/412 [21:47<00:00,  3.17s/it][1,0]<stderr>:\n","[1,0]<stderr>:06/19/2022 17:15:19 - INFO - __main__ -   all results written\n"]}],"source":["os.chdir('/content/drive/MyDrive/Colab projects/VideoQA research projects/ALPRO(Testing)/ALPRO-main/run_scripts')\n","!bash inf_msvd_qa_batch.sh"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jLrlScz7pDSB"},"outputs":[],"source":["os.chdir('/content/drive/MyDrive/Colab projects/VideoQA research projects/ALPRO(Testing)/ALPRO-main/run_scripts')\n","#!bash ft_msvd_qa.sh"]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/Colab projects/VideoQA research projects/ALPRO(Testing)/ALPRO-main/run_scripts')\n","!bash ft_msrvtt_qa.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGf_M8DKm8-b","outputId":"c4a8f631-3b8f-4824-cb22-be1333f06f7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/env/python:/content/drive/MyDrive/Colab projects/VideoQA research projects/ALPRO(Testing)/ALPRO-main\n","[1,0]<stderr>:06/21/2022 00:45:55 - INFO - __main__ -   device: cuda:0 n_gpu: 1, rank: 0, 16-bits training: False\n","[1,0]<stderr>:06/21/2022 00:45:55 - INFO - __main__ -   Setup model...\n","[1,0]<stderr>:06/21/2022 00:45:56 - INFO - __main__ -   setup e2e model\n","[1,0]<stderr>:06/21/2022 00:45:56 - INFO - __main__ -   Initializing TimeSformer with img_size=224, patch_size=16, num_frames=16\n","Downloading: 100%|██████████| 420M/420M [00:05<00:00, 80.9MB/s][1,0]<stderr>:\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","[1,0]<stderr>:- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['bert.pooler.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","[1,0]<stderr>:- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","[1,0]<stderr>:- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[1,0]<stderr>:06/21/2022 00:46:07 - INFO - __main__ -   Loading e2e weights from output/pretrain/alpro_pretrained_ckpt.pt\n","[1,0]<stderr>:06/21/2022 00:46:36 - INFO - __main__ -   The length of spatial position embedding matches. No need to resize.\n","[1,0]<stderr>:06/21/2022 00:46:36 - INFO - root -   Resizing temporal position embedding from 4 to 16\n","[1,0]<stderr>:06/21/2022 00:46:37 - INFO - __main__ -   You can ignore the keys with `num_batches_tracked` or from task heads\n","[1,0]<stderr>:06/21/2022 00:46:37 - INFO - __main__ -   Keys in loaded but not in model:\n","[1,0]<stderr>:06/21/2022 00:46:37 - INFO - __main__ -   In total 474, ['mpm_head.0.bias', 'mpm_head.0.weight', 'mpm_head.2.bias', 'mpm_head.2.weight', 'teacher_model.image_prompt_feat', 'teacher_model.itm_head.bias', 'teacher_model.itm_head.weight', 'teacher_model.temp', 'teacher_model.text_encoder.cls.predictions.bias', 'teacher_model.text_encoder.cls.predictions.decoder.bias', 'teacher_model.text_encoder.cls.predictions.decoder.weight', 'teacher_model.text_encoder.cls.predictions.transform.LayerNorm.bias', 'teacher_model.text_encoder.cls.predictions.transform.LayerNorm.weight', 'teacher_model.text_encoder.cls.predictions.transform.dense.bias', 'teacher_model.text_encoder.cls.predictions.transform.dense.weight', 'teacher_model.text_encoder.embeddings.LayerNorm.bias', 'teacher_model.text_encoder.embeddings.LayerNorm.weight', 'teacher_model.text_encoder.embeddings.position_embeddings.weight', 'teacher_model.text_encoder.embeddings.position_ids', 'teacher_model.text_encoder.embeddings.token_type_embeddings.weight', 'teacher_model.text_encoder.embeddings.word_embeddings.weight', 'teacher_model.text_encoder.encoder.layer.0.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.0.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.0.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.0.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.0.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.0.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.0.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.0.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.0.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.0.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.0.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.0.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.0.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.0.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.0.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.0.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.1.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.1.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.1.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.1.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.1.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.1.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.1.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.1.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.1.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.1.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.1.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.1.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.1.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.1.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.1.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.1.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.10.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.10.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.10.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.10.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.10.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.10.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.10.attention.self.value.bias', 'teacher_model.text_encoder.encoder.[1,0]<stderr>:layer.10.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.10.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.10.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.10.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.10.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.10.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.10.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.11.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.11.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.11.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.11.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.11.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.11.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.11.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.11.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.11.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.11.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.11.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.11.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.11.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.11.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.2.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.2.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.2.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.2.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.2.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.2.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.2.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.2.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.2.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.2.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.2.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.2.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.2.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.2.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.2.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.2.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.3.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.3.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.3.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.3.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.3.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.3.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.3.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.3.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.3.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.3.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.3.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.3.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.3.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.3.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'teacher_mo[1,0]<stderr>:del.text_encoder.encoder.layer.4.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.4.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.4.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.4.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.4.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.4.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.4.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.4.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.4.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.4.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.4.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.4.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.4.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.4.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.5.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.5.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.5.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.5.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.5.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.5.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.5.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.5.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.5.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.5.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.5.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.5.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.5.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.5.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.6.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.6.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.6.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.6.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.6.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.6.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.6.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.6.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.6.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.6.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.6.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.6.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.6.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.6.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.7.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.7.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.7.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.7.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.7.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.7.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.7.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.7.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.7.intermediate.dense.bias[1,0]<stderr>:', 'teacher_model.text_encoder.encoder.layer.7.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.7.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.7.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.7.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.7.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.8.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.8.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.8.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.8.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.8.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.8.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.8.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.8.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.8.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.8.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.8.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.8.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.8.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.8.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.9.attention.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.9.attention.output.dense.weight', 'teacher_model.text_encoder.encoder.layer.9.attention.self.key.bias', 'teacher_model.text_encoder.encoder.layer.9.attention.self.key.weight', 'teacher_model.text_encoder.encoder.layer.9.attention.self.query.bias', 'teacher_model.text_encoder.encoder.layer.9.attention.self.query.weight', 'teacher_model.text_encoder.encoder.layer.9.attention.self.value.bias', 'teacher_model.text_encoder.encoder.layer.9.attention.self.value.weight', 'teacher_model.text_encoder.encoder.layer.9.intermediate.dense.bias', 'teacher_model.text_encoder.encoder.layer.9.intermediate.dense.weight', 'teacher_model.text_encoder.encoder.layer.9.output.LayerNorm.bias', 'teacher_model.text_encoder.encoder.layer.9.output.LayerNorm.weight', 'teacher_model.text_encoder.encoder.layer.9.output.dense.bias', 'teacher_model.text_encoder.encoder.layer.9.output.dense.weight', 'teacher_model.text_proj.bias', 'teacher_model.text_proj.weight', 'teacher_model.video_prompt_feat', 'teacher_model.vision_proj.bias', 'teacher_model.vision_proj.weight', 'teacher_model.visual_encoder.model.blocks.0.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.0.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.0.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.0.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.0.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.0.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.0.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.0.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.0.norm1.bias', 'teacher_model.visual_encoder.model.blocks.0.norm1.weight', 'teacher_model.visual_encoder.model.blocks.0.norm2.bias', 'teacher_model.visual_encoder.model.blocks.0.norm2.weight', 'teacher_model.visual_encoder.model.blocks.0.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.0.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.0.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.0.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.0.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.0.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.0.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.0.temporal_norm1.weigh[1,0]<stderr>:t', 'teacher_model.visual_encoder.model.blocks.1.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.1.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.1.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.1.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.1.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.1.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.1.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.1.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.1.norm1.bias', 'teacher_model.visual_encoder.model.blocks.1.norm1.weight', 'teacher_model.visual_encoder.model.blocks.1.norm2.bias', 'teacher_model.visual_encoder.model.blocks.1.norm2.weight', 'teacher_model.visual_encoder.model.blocks.1.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.1.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.1.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.1.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.1.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.1.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.1.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.1.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.10.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.10.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.10.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.10.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.10.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.10.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.10.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.10.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.10.norm1.bias', 'teacher_model.visual_encoder.model.blocks.10.norm1.weight', 'teacher_model.visual_encoder.model.blocks.10.norm2.bias', 'teacher_model.visual_encoder.model.blocks.10.norm2.weight', 'teacher_model.visual_encoder.model.blocks.10.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.10.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.10.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.10.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.10.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.10.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.10.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.10.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.11.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.11.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.11.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.11.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.11.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.11.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.11.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.11.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.11.norm1.bias', 'teacher_model.visual_encoder.model.blocks.11.norm1.weight', 'teacher_model.visual_encoder.model.blocks.11.norm2.bias', 'teacher_model.visual_encoder.model.blocks.11.norm2.weight', 'teacher_model.visual_encoder.model.blocks.11.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.11.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.11.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.11.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.11.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.11.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.11.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.11.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.2.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.2.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.2.attn.qkv.bias', 'teacher_model.visu[1,0]<stderr>:al_encoder.model.blocks.2.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.2.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.2.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.2.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.2.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.2.norm1.bias', 'teacher_model.visual_encoder.model.blocks.2.norm1.weight', 'teacher_model.visual_encoder.model.blocks.2.norm2.bias', 'teacher_model.visual_encoder.model.blocks.2.norm2.weight', 'teacher_model.visual_encoder.model.blocks.2.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.2.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.2.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.2.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.2.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.2.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.2.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.2.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.3.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.3.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.3.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.3.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.3.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.3.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.3.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.3.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.3.norm1.bias', 'teacher_model.visual_encoder.model.blocks.3.norm1.weight', 'teacher_model.visual_encoder.model.blocks.3.norm2.bias', 'teacher_model.visual_encoder.model.blocks.3.norm2.weight', 'teacher_model.visual_encoder.model.blocks.3.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.3.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.3.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.3.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.3.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.3.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.3.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.3.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.4.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.4.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.4.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.4.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.4.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.4.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.4.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.4.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.4.norm1.bias', 'teacher_model.visual_encoder.model.blocks.4.norm1.weight', 'teacher_model.visual_encoder.model.blocks.4.norm2.bias', 'teacher_model.visual_encoder.model.blocks.4.norm2.weight', 'teacher_model.visual_encoder.model.blocks.4.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.4.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.4.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.4.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.4.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.4.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.4.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.4.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.5.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.5.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.5.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.5.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.5.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.5.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.5.mlp.fc2.bias', 'teacher_model.visual_en[1,0]<stderr>:coder.model.blocks.5.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.5.norm1.bias', 'teacher_model.visual_encoder.model.blocks.5.norm1.weight', 'teacher_model.visual_encoder.model.blocks.5.norm2.bias', 'teacher_model.visual_encoder.model.blocks.5.norm2.weight', 'teacher_model.visual_encoder.model.blocks.5.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.5.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.5.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.5.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.5.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.5.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.5.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.5.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.6.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.6.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.6.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.6.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.6.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.6.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.6.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.6.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.6.norm1.bias', 'teacher_model.visual_encoder.model.blocks.6.norm1.weight', 'teacher_model.visual_encoder.model.blocks.6.norm2.bias', 'teacher_model.visual_encoder.model.blocks.6.norm2.weight', 'teacher_model.visual_encoder.model.blocks.6.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.6.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.6.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.6.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.6.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.6.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.6.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.6.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.7.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.7.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.7.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.7.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.7.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.7.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.7.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.7.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.7.norm1.bias', 'teacher_model.visual_encoder.model.blocks.7.norm1.weight', 'teacher_model.visual_encoder.model.blocks.7.norm2.bias', 'teacher_model.visual_encoder.model.blocks.7.norm2.weight', 'teacher_model.visual_encoder.model.blocks.7.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.7.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.7.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.7.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.7.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.7.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.7.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.7.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.8.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.8.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.8.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.8.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.8.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.8.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.8.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.8.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.8.norm1.bias', 'teacher_model.visual_encoder.model.blocks.8.norm1.weight', 'teacher_model.visual_encoder.model.blocks.8.norm2.bias', 'teacher_model.visual_encoder.model.[1,0]<stderr>:blocks.8.norm2.weight', 'teacher_model.visual_encoder.model.blocks.8.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.8.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.8.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.8.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.8.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.8.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.8.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.8.temporal_norm1.weight', 'teacher_model.visual_encoder.model.blocks.9.attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.9.attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.9.attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.9.attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.9.mlp.fc1.bias', 'teacher_model.visual_encoder.model.blocks.9.mlp.fc1.weight', 'teacher_model.visual_encoder.model.blocks.9.mlp.fc2.bias', 'teacher_model.visual_encoder.model.blocks.9.mlp.fc2.weight', 'teacher_model.visual_encoder.model.blocks.9.norm1.bias', 'teacher_model.visual_encoder.model.blocks.9.norm1.weight', 'teacher_model.visual_encoder.model.blocks.9.norm2.bias', 'teacher_model.visual_encoder.model.blocks.9.norm2.weight', 'teacher_model.visual_encoder.model.blocks.9.temporal_attn.proj.bias', 'teacher_model.visual_encoder.model.blocks.9.temporal_attn.proj.weight', 'teacher_model.visual_encoder.model.blocks.9.temporal_attn.qkv.bias', 'teacher_model.visual_encoder.model.blocks.9.temporal_attn.qkv.weight', 'teacher_model.visual_encoder.model.blocks.9.temporal_fc.bias', 'teacher_model.visual_encoder.model.blocks.9.temporal_fc.weight', 'teacher_model.visual_encoder.model.blocks.9.temporal_norm1.bias', 'teacher_model.visual_encoder.model.blocks.9.temporal_norm1.weight', 'teacher_model.visual_encoder.model.cls_token', 'teacher_model.visual_encoder.model.head.bias', 'teacher_model.visual_encoder.model.head.weight', 'teacher_model.visual_encoder.model.norm.bias', 'teacher_model.visual_encoder.model.norm.weight', 'teacher_model.visual_encoder.model.patch_embed.proj.bias', 'teacher_model.visual_encoder.model.patch_embed.proj.weight', 'teacher_model.visual_encoder.model.pos_embed', 'teacher_model.visual_encoder.model.time_embed', 'text_encoder.cls.predictions.bias', 'text_encoder.cls.predictions.decoder.bias', 'text_encoder.cls.predictions.decoder.weight', 'text_encoder.cls.predictions.transform.LayerNorm.bias', 'text_encoder.cls.predictions.transform.LayerNorm.weight', 'text_encoder.cls.predictions.transform.dense.bias', 'text_encoder.cls.predictions.transform.dense.weight']\n","[1,0]<stderr>:06/21/2022 00:46:37 - INFO - __main__ -   Keys in model but not in loaded:\n","[1,0]<stderr>:06/21/2022 00:46:37 - INFO - __main__ -   In total 4, ['classifier.0.bias', 'classifier.0.weight', 'classifier.2.bias', 'classifier.2.weight']\n","[1,0]<stderr>:06/21/2022 00:46:37 - INFO - __main__ -   Keys in model and loaded, but shape mismatched:\n","[1,0]<stderr>:06/21/2022 00:46:37 - INFO - __main__ -   In total 0, []\n","[1,0]<stderr>:06/21/2022 00:46:54 - INFO - __main__ -   Setup model done!\n","[1,0]<stderr>:/content/drive/MyDrive/Colab projects/VideoQA research projects/ALPRO(Testing)/ALPRO-main/src/optimization/adamw.py:77: UserWarning: This overload of add_ is deprecated:\n","[1,0]<stderr>:\tadd_(Number alpha, Tensor other)\n","[1,0]<stderr>:Consider using one of the following signatures instead:\n","[1,0]<stderr>:\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n","[1,0]<stderr>:  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","[1,0]<stderr>:06/21/2022 00:46:58 - INFO - __main__ -   Init. train_loader and val_loader...\n","[1,0]<stderr>:06/21/2022 00:47:00 - INFO - __main__ -   Loaded data size 149075\n","[1,0]<stderr>:06/21/2022 00:47:00 - INFO - __main__ -   datalist 149075\n","[1,0]<stderr>:06/21/2022 00:47:00 - INFO - __main__ -   grouped 6513\n","[1,0]<stderr>:06/21/2022 00:47:00 - INFO - __main__ -   group_datalist 149075\n","[1,0]<stderr>:06/21/2022 00:47:00 - INFO - __main__ -   is_train True, dataset size 149075 groups, each group 1\n","[1,0]<stderr>:06/21/2022 00:47:01 - INFO - __main__ -   Loaded data size 12278\n","[1,0]<stderr>:06/21/2022 00:47:01 - INFO - __main__ -   datalist 12278\n","[1,0]<stderr>:06/21/2022 00:47:01 - INFO - __main__ -   grouped 497\n","[1,0]<stderr>:06/21/2022 00:47:01 - INFO - __main__ -   group_datalist 12278\n","[1,0]<stderr>:06/21/2022 00:47:01 - INFO - __main__ -   is_train False, dataset size 12278 groups, each group 1\n","[1,0]<stderr>:06/21/2022 00:47:03 - INFO - __main__ -   found previous checkpoint. try to resume...\n","[1,0]<stderr>:06/21/2022 00:47:03 - INFO - __main__ -   TrainingRestorer restore trial NO. 0\n","[1,0]<stderr>:06/21/2022 00:47:20 - INFO - __main__ -   resume training from step 4256\n","[1,0]<stderr>:06/21/2022 00:47:20 - INFO - __main__ -   Saving training meta...\n","[1,0]<stderr>:06/21/2022 00:47:21 - INFO - __main__ -   Saving code from /content/drive/MyDrive/Colab projects/VideoQA research projects/ALPRO(Testing)/ALPRO-main to output/downstreams/msrvtt_qa/private/20220619201636/code.zip...\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -   Saving code done.\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -   Saving training done...\n","  0%|          | 0/26621 [00:00<?, ?it/s][1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -   {'debug': False, 'data_ratio': 1.0, 'model_config': 'config_release/base_model.json', 'tokenizer_dir': 'ext/bert-base-uncased/', 'output_dir': 'output/downstreams/msrvtt_qa/private/20220619201636', 'max_txt_len': 40, 'img_pixel_mean': [0.48145466, 0.4578275, 0.40821073], 'img_pixel_std': [0.26862954, 0.26130258, 0.27577711], 'img_input_format': 'RGB', 'max_n_example_per_group': 1, 'fps': 1, 'num_frm': 16, 'frm_sampling_strategy': 'rand', 'train_n_clips': 1, 'score_agg_func': 'mean', 'random_sample_clips': 1, 'train_batch_size': 7, 'val_batch_size': 7, 'gradient_accumulation_steps': 8, 'learning_rate': 5e-05, 'log_interval': 500, 'num_valid': 50, 'min_valid_steps': 50, 'save_steps_ratio': 0.01, 'num_train_epochs': 10, 'optim': 'adamw', 'betas': [0.9, 0.98], 'decay': 'linear', 'dropout': 0.1, 'weight_decay': 0.001, 'grad_norm': 5.0, 'warmup_ratio': 0.1, 'transformer_lr_mul': 1.0, 'step_decay_epochs': None, 'model_type': 'pretrain', 'timesformer_model_cfg': '', 'e2e_weights_path': 'output/pretrain/alpro_pretrained_ckpt.pt', 'clip_init': 0, 'bert_weights_path': None, 'inference_model_step': -1, 'do_inference': False, 'inference_split': 'val', 'inference_txt_db': None, 'inference_img_db': None, 'inference_batch_size': 64, 'inference_n_clips': 1, 'seed': 42, 'fp16': False, 'n_workers': 4, 'pin_mem': True, 'config': 'config_release/msrvtt_qa.json', 'task': 'msrvtt_qa', 'loss_type': 'ce', 'classifier': 'mlp', 'cls_hidden_scale': 2, 'ans2label_path': 'data/msrvtt_qa/txt/train_ans2label.json', 'train_datasets': [{'name': 'msrvtt_qa', 'txt': {'msrvtt_qa': 'data/msrvtt_qa/txt/train.jsonl'}, 'img': 'data/msrvtt_qa/videos'}], 'val_datasets': [{'name': 'msrvtt_qa', 'txt': {'msrvtt_qa': 'data/msrvtt_qa/txt/val.jsonl'}, 'img': 'data/msrvtt_qa/videos'}], 'crop_img_size': 224, 'resize_size': 256, 'visual_model_cfg': 'config_release/timesformer_divst_8x32_224_k600_gc.json', 'cnn_lr_decay': 'linear', 'num_workers': 4, 'num_labels': 1500, 'n_gpu': 1, 'num_train_steps': 26621, 'valid_steps': 550}\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -   Starting training...\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -   ***** Running training with 1 GPUs *****\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -     Single-GPU Non-Accumulated batch size = 7\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -     max_n_example_per_group = 1\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -     Accumulate steps = 8\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -     Total batch size = #GPUs * Single-GPU batch size * max_n_example_per_group * Accumulate steps [Image] = 56\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -     Total #epochs = 10\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -     Total #steps = 26621\n","[1,0]<stderr>:06/21/2022 00:53:46 - INFO - __main__ -     Validate every 550 steps, in total 49 times\n"," 17%|█▋        | 4400/26621 [40:58<105:08:36, 17.03s/it][1,0]<stderr>:06/21/2022 01:34:45 - INFO - __main__ -   Step 4400: start validation\n","[1,0]<stderr>:\n","  0%|          | 0/1754 [00:00<?, ?it/s]\u001b[A[1,0]<stderr>:\n","  0%|          | 1/1754 [00:02<1:14:58,  2.57s/it]\u001b[A[1,0]<stderr>:\n","  0%|          | 2/1754 [00:03<40:09,  1.38s/it]  \u001b[A[1,0]<stderr>:\n","  0%|          | 3/1754 [00:03<30:41,  1.05s/it]\u001b[A[1,0]<stderr>:\n","  0%|          | 4/1754 [00:04<29:23,  1.01s/it]\u001b[A[1,0]<stderr>:\n","  0%|          | 5/1754 [00:05<24:33,  1.19it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  0%|          | 6/1754 [00:05<21:34,  1.35it/s]\u001b[A[1,0]<stderr>:\n","  0%|          | 7/1754 [00:06<19:41,  1.48it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  0%|          | 8/1754 [00:06<18:29,  1.57it/s]\u001b[A[1,0]<stderr>:\n","  1%|          | 9/1754 [00:07<17:40,  1.64it/s]\u001b[A[1,0]<stderr>:\n","  1%|          | 10/1754 [00:07<17:05,  1.70it/s]\u001b[A[1,0]<stderr>:\n","  1%|          | 11/1754 [00:08<16:40,  1.74it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|          | 12/1754 [00:09<16:26,  1.77it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|          | 13/1754 [00:09<16:15,  1.78it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|          | 14/1754 [00:10<16:07,  1.80it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|          | 15/1754 [00:11<27:01,  1.07it/s]\u001b[A[1,0]<stderr>:\n","  1%|          | 16/1754 [00:12<23:41,  1.22it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|          | 17/1754 [00:13<21:19,  1.36it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|          | 18/1754 [00:13<19:40,  1.47it/s]\u001b[A[1,0]<stderr>:\n","  1%|          | 19/1754 [00:14<18:29,  1.56it/s]\u001b[A[1,0]<stderr>:\n","  1%|          | 20/1754 [00:14<17:41,  1.63it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|          | 21/1754 [00:15<17:06,  1.69it/s]\u001b[A[1,0]<stderr>:\n","  1%|▏         | 22/1754 [00:15<16:40,  1.73it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|▏         | 23/1754 [00:16<16:23,  1.76it/s]\u001b[A[1,0]<stderr>:\n","  1%|▏         | 24/1754 [00:16<16:13,  1.78it/s]\u001b[A[1,0]<stderr>:\n","  1%|▏         | 25/1754 [00:17<16:02,  1.80it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  1%|▏         | 26/1754 [00:17<15:56,  1.81it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  2%|▏         | 27/1754 [00:18<15:53,  1.81it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 28/1754 [00:19<15:51,  1.81it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 29/1754 [00:19<15:46,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  2%|▏         | 30/1754 [00:20<15:46,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  2%|▏         | 31/1754 [00:20<15:44,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  2%|▏         | 32/1754 [00:21<15:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 33/1754 [00:21<15:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  2%|▏         | 34/1754 [00:22<15:41,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  2%|▏         | 35/1754 [00:22<15:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 36/1754 [00:23<15:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 37/1754 [00:24<15:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 38/1754 [00:24<15:34,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 39/1754 [00:25<15:31,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 40/1754 [00:25<15:30,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  2%|▏         | 41/1754 [00:26<15:32,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 42/1754 [00:26<15:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  2%|▏         | 43/1754 [00:27<15:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 44/1754 [00:27<15:34,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  3%|▎         | 45/1754 [00:28<15:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 46/1754 [00:28<15:34,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  3%|▎         | 47/1754 [00:29<15:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 48/1754 [00:30<15:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 49/1754 [00:30<15:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 50/1754 [00:31<15:28,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 51/1754 [00:31<15:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 52/1754 [00:32<15:28,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  3%|▎         | 53/1754 [00:32<15:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 54/1754 [00:33<15:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 55/1754 [00:33<15:27,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  3%|▎         | 56/1754 [00:34<15:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 57/1754 [00:34<15:29,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  3%|▎         | 58/1754 [00:35<15:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 59/1754 [00:36<15:24,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  3%|▎         | 60/1754 [00:36<15:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  3%|▎         | 61/1754 [00:37<15:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▎         | 62/1754 [00:37<15:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▎         | 63/1754 [00:38<15:21,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  4%|▎         | 64/1754 [00:38<15:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▎         | 65/1754 [00:39<15:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 66/1754 [00:39<15:19,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 67/1754 [00:40<15:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 68/1754 [00:40<15:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 69/1754 [00:41<15:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 70/1754 [00:42<15:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 71/1754 [00:42<15:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 72/1754 [00:43<15:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 73/1754 [00:43<15:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 74/1754 [00:44<15:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 75/1754 [00:44<15:14,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  4%|▍         | 76/1754 [00:45<15:12,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 77/1754 [00:45<15:13,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  4%|▍         | 78/1754 [00:46<15:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  5%|▍         | 79/1754 [00:46<15:12,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  5%|▍         | 80/1754 [00:47<15:10,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  5%|▍         | 81/1754 [00:48<15:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  5%|▍         | 82/1754 [00:48<15:11,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  5%|▍         | 83/1754 [00:49<15:08,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  5%|▍         | 84/1754 [00:49<15:09,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  5%|▍         | 85/1754 [00:50<15:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  5%|▍         | 86/1754 [00:50<15:14,  1.82it/s]\u001b[A[1,0]<stderr>:\n","  5%|▍         | 87/1754 [00:51<15:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  5%|▌         | 88/1754 [00:51<15:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  5%|▌         | 89/1754 [00:52<15:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  5%|▌         | 90/1754 [00:52<15:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  5%|▌         | 91/1754 [00:53<15:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  5%|▌         | 92/1754 [00:54<15:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  5%|▌         | 93/1754 [00:54<15:10,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  5%|▌         | 94/1754 [00:55<15:10,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  5%|▌         | 95/1754 [00:55<15:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  5%|▌         | 96/1754 [00:56<15:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 97/1754 [00:56<15:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  6%|▌         | 98/1754 [00:57<15:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  6%|▌         | 99/1754 [00:57<15:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  6%|▌         | 100/1754 [00:58<15:01,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 101/1754 [00:58<15:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 102/1754 [00:59<15:04,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 103/1754 [01:00<15:04,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 104/1754 [01:00<15:04,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 105/1754 [01:01<15:05,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 106/1754 [01:01<15:04,  1.82it/s]\u001b[A[1,0]<stderr>:\n","  6%|▌         | 107/1754 [01:02<15:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 108/1754 [01:02<15:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▌         | 109/1754 [01:03<15:01,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  6%|▋         | 110/1754 [01:03<15:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  6%|▋         | 111/1754 [01:04<14:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  6%|▋         | 112/1754 [01:04<14:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  6%|▋         | 113/1754 [01:05<14:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  6%|▋         | 114/1754 [01:06<14:52,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  7%|▋         | 115/1754 [01:06<14:54,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  7%|▋         | 116/1754 [01:07<14:54,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  7%|▋         | 117/1754 [01:07<14:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 118/1754 [01:08<14:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 119/1754 [01:08<14:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 120/1754 [01:09<14:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 121/1754 [01:09<14:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 122/1754 [01:10<14:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  7%|▋         | 123/1754 [01:10<14:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  7%|▋         | 124/1754 [01:11<14:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 125/1754 [01:12<14:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 126/1754 [01:12<14:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 127/1754 [01:13<14:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 128/1754 [01:13<14:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  7%|▋         | 129/1754 [01:14<14:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 130/1754 [01:14<14:51,  1.82it/s]\u001b[A[1,0]<stderr>:\n","  7%|▋         | 131/1754 [01:15<14:49,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  8%|▊         | 132/1754 [01:15<14:49,  1.82it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 133/1754 [01:16<14:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 134/1754 [01:16<14:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 135/1754 [01:17<14:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  8%|▊         | 136/1754 [01:18<14:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  8%|▊         | 137/1754 [01:18<14:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 138/1754 [01:19<14:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 139/1754 [01:19<14:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 140/1754 [01:20<14:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 141/1754 [01:20<14:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  8%|▊         | 142/1754 [01:21<14:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 143/1754 [01:21<14:37,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 144/1754 [01:22<14:36,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 145/1754 [01:22<14:37,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  8%|▊         | 146/1754 [01:23<14:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 147/1754 [01:24<14:38,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  8%|▊         | 148/1754 [01:24<14:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  8%|▊         | 149/1754 [01:25<14:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▊         | 150/1754 [01:25<14:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▊         | 151/1754 [01:26<14:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▊         | 152/1754 [01:26<14:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▊         | 153/1754 [01:27<14:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 154/1754 [01:27<14:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 155/1754 [01:28<14:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 156/1754 [01:29<14:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 157/1754 [01:29<14:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 158/1754 [01:30<14:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 159/1754 [01:30<14:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 160/1754 [01:31<14:27,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  9%|▉         | 161/1754 [01:31<14:28,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  9%|▉         | 162/1754 [01:32<14:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 163/1754 [01:32<14:26,  1.84it/s]\u001b[A[1,0]<stderr>:\n","  9%|▉         | 164/1754 [01:33<14:23,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  9%|▉         | 165/1754 [01:33<14:25,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n","  9%|▉         | 166/1754 [01:34<14:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 167/1754 [01:34<14:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 168/1754 [01:35<14:23,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 169/1754 [01:36<14:23,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 170/1754 [01:36<14:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 171/1754 [01:37<14:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 172/1754 [01:37<14:22,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 173/1754 [01:38<14:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 174/1754 [01:38<14:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|▉         | 175/1754 [01:39<14:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|█         | 176/1754 [01:39<14:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|█         | 177/1754 [01:40<14:18,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 10%|█         | 178/1754 [01:40<14:17,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 10%|█         | 179/1754 [01:41<14:17,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 10%|█         | 180/1754 [01:42<14:19,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 10%|█         | 181/1754 [01:42<14:20,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 10%|█         | 182/1754 [01:43<14:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|█         | 183/1754 [01:43<14:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 10%|█         | 184/1754 [01:44<14:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 185/1754 [01:44<14:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 186/1754 [01:45<14:14,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 187/1754 [01:45<14:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 188/1754 [01:46<14:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 189/1754 [01:46<14:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 11%|█         | 190/1754 [01:47<14:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 11%|█         | 191/1754 [01:48<14:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 11%|█         | 192/1754 [01:48<14:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 193/1754 [01:49<14:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 11%|█         | 194/1754 [01:49<14:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 195/1754 [01:50<14:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 196/1754 [01:50<14:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█         | 197/1754 [01:51<14:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 11%|█▏        | 198/1754 [01:51<14:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 11%|█▏        | 199/1754 [01:52<14:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 11%|█▏        | 200/1754 [01:53<14:08,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 11%|█▏        | 201/1754 [01:53<14:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 202/1754 [01:54<14:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 203/1754 [01:54<14:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 204/1754 [01:55<14:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 205/1754 [01:55<14:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 206/1754 [01:56<14:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 207/1754 [01:56<14:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 208/1754 [01:57<14:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 209/1754 [01:57<14:06,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 210/1754 [01:58<15:12,  1.69it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 211/1754 [01:59<14:51,  1.73it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 212/1754 [01:59<14:36,  1.76it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 213/1754 [02:00<14:25,  1.78it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 214/1754 [02:00<14:16,  1.80it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 215/1754 [02:01<14:11,  1.81it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 216/1754 [02:01<14:06,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 217/1754 [02:02<14:03,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 218/1754 [02:02<14:02,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 12%|█▏        | 219/1754 [02:03<14:01,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 220/1754 [02:04<14:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 221/1754 [02:04<14:01,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 222/1754 [02:05<13:59,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 223/1754 [02:05<13:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 224/1754 [02:06<13:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 225/1754 [02:06<13:54,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 226/1754 [02:07<13:53,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 227/1754 [02:07<13:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 228/1754 [02:08<13:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 229/1754 [02:08<13:50,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 230/1754 [02:09<13:49,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 231/1754 [02:10<13:48,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 232/1754 [02:10<13:49,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 233/1754 [02:11<13:48,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 234/1754 [02:11<13:47,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 235/1754 [02:12<13:46,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 13%|█▎        | 236/1754 [02:12<13:45,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▎        | 237/1754 [02:13<13:46,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 14%|█▎        | 238/1754 [02:13<13:46,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 14%|█▎        | 239/1754 [02:14<13:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▎        | 240/1754 [02:14<13:44,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 14%|█▎        | 241/1754 [02:15<13:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 242/1754 [02:16<13:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 243/1754 [02:16<13:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 244/1754 [02:17<13:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 245/1754 [02:17<13:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 246/1754 [02:18<13:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 247/1754 [02:18<13:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 248/1754 [02:19<13:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 249/1754 [02:19<13:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 250/1754 [02:20<13:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 251/1754 [02:21<13:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 252/1754 [02:21<13:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 253/1754 [02:22<13:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 14%|█▍        | 254/1754 [02:22<13:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 255/1754 [02:23<13:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 256/1754 [02:23<13:38,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 257/1754 [02:24<13:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 258/1754 [02:24<13:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 259/1754 [02:25<13:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 260/1754 [02:25<13:35,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 261/1754 [02:26<13:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 262/1754 [02:27<13:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▍        | 263/1754 [02:27<13:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▌        | 264/1754 [02:28<13:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▌        | 265/1754 [02:28<13:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▌        | 266/1754 [02:29<13:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▌        | 267/1754 [02:29<13:31,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 15%|█▌        | 268/1754 [02:30<13:31,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 15%|█▌        | 269/1754 [02:30<13:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▌        | 270/1754 [02:31<13:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 15%|█▌        | 271/1754 [02:31<13:27,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 272/1754 [02:32<13:25,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 273/1754 [02:33<13:23,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 274/1754 [02:33<13:23,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 275/1754 [02:34<13:23,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 276/1754 [02:34<13:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 277/1754 [02:35<13:21,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 278/1754 [02:35<13:20,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 279/1754 [02:36<13:21,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 280/1754 [02:36<13:21,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 281/1754 [02:37<13:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 282/1754 [02:37<13:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 283/1754 [02:38<13:20,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 284/1754 [02:38<13:21,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 16%|█▌        | 285/1754 [02:39<13:22,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 16%|█▋        | 286/1754 [02:40<13:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▋        | 287/1754 [02:40<13:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 16%|█▋        | 288/1754 [02:41<13:20,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 16%|█▋        | 289/1754 [02:41<13:20,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 290/1754 [02:42<13:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 291/1754 [02:42<13:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 292/1754 [02:43<13:19,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 293/1754 [02:43<13:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 294/1754 [02:44<13:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 295/1754 [02:45<13:19,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 296/1754 [02:45<13:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 297/1754 [02:46<13:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 298/1754 [02:46<13:12,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 299/1754 [02:47<13:11,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 300/1754 [02:47<13:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 301/1754 [02:48<13:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 302/1754 [02:48<13:15,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 303/1754 [02:49<13:15,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 304/1754 [02:49<13:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 305/1754 [02:50<13:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 17%|█▋        | 306/1754 [02:51<13:12,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 307/1754 [02:51<13:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 308/1754 [02:52<13:08,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 309/1754 [02:52<13:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 310/1754 [02:53<13:08,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 311/1754 [02:53<13:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 312/1754 [02:54<13:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 313/1754 [02:54<13:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 314/1754 [02:55<13:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 315/1754 [02:55<13:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 316/1754 [02:56<13:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 317/1754 [02:57<13:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 318/1754 [02:57<13:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 319/1754 [02:58<13:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 320/1754 [02:58<13:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 321/1754 [02:59<13:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 322/1754 [02:59<13:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 323/1754 [03:00<13:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 18%|█▊        | 324/1754 [03:00<13:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▊        | 325/1754 [03:01<13:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▊        | 326/1754 [03:01<12:57,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▊        | 327/1754 [03:02<12:57,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▊        | 328/1754 [03:03<12:55,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 329/1754 [03:03<12:53,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 330/1754 [03:04<12:53,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 331/1754 [03:04<12:54,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 332/1754 [03:05<12:56,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 333/1754 [03:05<12:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 334/1754 [03:06<12:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 335/1754 [03:06<12:53,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 336/1754 [03:07<12:52,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 337/1754 [03:07<12:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 338/1754 [03:08<12:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 339/1754 [03:09<12:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 340/1754 [03:09<12:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 341/1754 [03:10<12:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 19%|█▉        | 342/1754 [03:10<12:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|█▉        | 343/1754 [03:11<12:51,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|█▉        | 344/1754 [03:11<12:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|█▉        | 345/1754 [03:12<12:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|█▉        | 346/1754 [03:12<12:46,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 20%|█▉        | 347/1754 [03:13<12:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 20%|█▉        | 348/1754 [03:13<12:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|█▉        | 349/1754 [03:14<12:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|█▉        | 350/1754 [03:15<12:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|██        | 351/1754 [03:15<12:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|██        | 352/1754 [03:16<12:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|██        | 353/1754 [03:16<12:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|██        | 354/1754 [03:17<12:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 20%|██        | 355/1754 [03:17<12:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 20%|██        | 356/1754 [03:18<12:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|██        | 357/1754 [03:18<12:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 20%|██        | 358/1754 [03:19<12:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 20%|██        | 359/1754 [03:19<12:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 21%|██        | 360/1754 [03:20<12:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██        | 361/1754 [03:21<12:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██        | 362/1754 [03:21<12:38,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 21%|██        | 363/1754 [03:22<12:38,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 21%|██        | 364/1754 [03:22<12:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██        | 365/1754 [03:23<12:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██        | 366/1754 [03:23<12:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 21%|██        | 367/1754 [03:24<12:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██        | 368/1754 [03:24<12:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██        | 369/1754 [03:25<12:34,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██        | 370/1754 [03:25<12:33,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 21%|██        | 371/1754 [03:26<12:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██        | 372/1754 [03:27<12:37,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 21%|██▏       | 373/1754 [03:27<12:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██▏       | 374/1754 [03:28<12:33,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 21%|██▏       | 375/1754 [03:28<12:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██▏       | 376/1754 [03:29<12:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 21%|██▏       | 377/1754 [03:29<12:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 378/1754 [03:30<12:32,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 379/1754 [03:30<12:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 380/1754 [03:31<12:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 381/1754 [03:31<12:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 382/1754 [03:32<12:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 383/1754 [03:33<12:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 384/1754 [03:33<12:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 385/1754 [03:34<12:26,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 386/1754 [03:34<12:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 387/1754 [03:35<12:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 388/1754 [03:35<12:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 389/1754 [03:36<12:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 390/1754 [03:36<12:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 391/1754 [03:37<12:25,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 392/1754 [03:37<12:24,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 393/1754 [03:38<12:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 22%|██▏       | 394/1754 [03:39<12:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 395/1754 [03:39<12:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 396/1754 [03:40<12:20,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 397/1754 [03:40<12:24,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 398/1754 [03:41<12:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 399/1754 [03:41<12:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 400/1754 [03:42<12:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 401/1754 [03:42<12:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 402/1754 [03:43<12:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 403/1754 [03:43<12:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 404/1754 [03:44<12:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 405/1754 [03:45<12:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 406/1754 [03:45<12:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 407/1754 [03:46<12:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 408/1754 [03:46<12:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 409/1754 [03:47<12:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 410/1754 [03:47<12:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 411/1754 [03:48<12:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 23%|██▎       | 412/1754 [03:48<12:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▎       | 413/1754 [03:49<12:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 24%|██▎       | 414/1754 [03:50<12:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▎       | 415/1754 [03:50<12:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▎       | 416/1754 [03:51<12:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 417/1754 [03:51<12:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 418/1754 [03:52<12:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 419/1754 [03:52<12:07,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 420/1754 [03:53<12:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 421/1754 [03:53<12:05,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 422/1754 [03:54<12:04,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 423/1754 [03:54<12:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 424/1754 [03:55<12:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 425/1754 [03:56<12:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 426/1754 [03:56<12:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 427/1754 [03:57<12:02,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 428/1754 [03:57<12:01,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 24%|██▍       | 429/1754 [03:58<12:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 430/1754 [03:58<12:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 431/1754 [03:59<12:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 432/1754 [03:59<12:00,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 433/1754 [04:00<11:59,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 434/1754 [04:00<12:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 435/1754 [04:01<11:59,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 436/1754 [04:02<12:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 437/1754 [04:02<12:02,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 25%|██▍       | 438/1754 [04:03<12:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 439/1754 [04:03<11:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 440/1754 [04:04<11:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 441/1754 [04:04<11:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 442/1754 [04:05<11:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 443/1754 [04:05<11:54,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 444/1754 [04:06<11:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 445/1754 [04:06<11:52,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 446/1754 [04:07<11:51,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 25%|██▌       | 447/1754 [04:08<11:49,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 448/1754 [04:08<11:49,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 449/1754 [04:09<11:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 450/1754 [04:09<11:51,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 451/1754 [04:10<11:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 452/1754 [04:10<11:53,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 453/1754 [04:11<11:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 454/1754 [04:11<11:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 455/1754 [04:12<11:52,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 456/1754 [04:12<11:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 457/1754 [04:13<11:49,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 458/1754 [04:14<11:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 459/1754 [04:14<11:45,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 26%|██▌       | 460/1754 [04:15<11:45,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 26%|██▋       | 461/1754 [04:15<11:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▋       | 462/1754 [04:16<11:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▋       | 463/1754 [04:16<11:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 26%|██▋       | 464/1754 [04:17<11:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 465/1754 [04:17<11:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 466/1754 [04:18<11:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 467/1754 [04:18<11:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 468/1754 [04:19<11:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 469/1754 [04:20<11:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 470/1754 [04:20<11:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 471/1754 [04:21<11:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 472/1754 [04:21<11:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 473/1754 [04:22<11:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 474/1754 [04:22<11:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 475/1754 [04:23<11:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 476/1754 [04:23<11:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 477/1754 [04:24<11:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 478/1754 [04:24<11:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 479/1754 [04:25<11:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 480/1754 [04:26<11:33,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 481/1754 [04:26<11:32,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 27%|██▋       | 482/1754 [04:27<11:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 483/1754 [04:27<11:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 484/1754 [04:28<11:35,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 485/1754 [04:28<11:35,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 486/1754 [04:29<11:35,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 487/1754 [04:29<11:35,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 488/1754 [04:30<11:34,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 489/1754 [04:30<11:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 490/1754 [04:31<11:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 491/1754 [04:32<11:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 492/1754 [04:32<11:28,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 493/1754 [04:33<11:28,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 494/1754 [04:33<11:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 495/1754 [04:34<11:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 496/1754 [04:34<11:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 497/1754 [04:35<11:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 498/1754 [04:35<11:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 28%|██▊       | 499/1754 [04:36<11:22,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 29%|██▊       | 500/1754 [04:36<11:22,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 29%|██▊       | 501/1754 [04:37<11:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▊       | 502/1754 [04:38<11:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▊       | 503/1754 [04:38<11:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▊       | 504/1754 [04:39<11:20,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 505/1754 [04:39<11:20,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 506/1754 [04:40<11:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 507/1754 [04:40<11:18,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 508/1754 [04:41<11:17,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 509/1754 [04:41<11:18,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 510/1754 [04:42<11:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 511/1754 [04:42<11:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 512/1754 [04:43<11:17,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 513/1754 [04:44<11:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 514/1754 [04:44<11:15,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 515/1754 [04:45<11:16,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 516/1754 [04:45<11:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 29%|██▉       | 517/1754 [04:46<11:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 518/1754 [04:46<11:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 519/1754 [04:47<11:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 520/1754 [04:47<11:12,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 521/1754 [04:48<11:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 522/1754 [04:48<11:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 523/1754 [04:49<11:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 524/1754 [04:50<11:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 525/1754 [04:50<11:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 30%|██▉       | 526/1754 [04:51<11:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|███       | 527/1754 [04:51<11:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 30%|███       | 528/1754 [04:52<11:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|███       | 529/1754 [04:52<11:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|███       | 530/1754 [04:53<11:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|███       | 531/1754 [04:53<11:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|███       | 532/1754 [04:54<11:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|███       | 533/1754 [04:54<11:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 30%|███       | 534/1754 [04:55<11:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███       | 535/1754 [04:56<11:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███       | 536/1754 [04:56<11:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███       | 537/1754 [04:57<11:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███       | 538/1754 [04:57<11:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 31%|███       | 539/1754 [04:58<11:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███       | 540/1754 [04:58<11:06,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 31%|███       | 541/1754 [04:59<11:04,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 31%|███       | 542/1754 [04:59<11:03,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 31%|███       | 543/1754 [05:00<11:03,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███       | 544/1754 [05:01<11:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███       | 545/1754 [05:01<11:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 31%|███       | 546/1754 [05:02<11:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 31%|███       | 547/1754 [05:02<10:59,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███       | 548/1754 [05:03<11:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 31%|███▏      | 549/1754 [05:03<10:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 31%|███▏      | 550/1754 [05:04<10:58,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███▏      | 551/1754 [05:04<10:57,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 31%|███▏      | 552/1754 [05:05<10:58,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 553/1754 [05:05<10:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 554/1754 [05:06<10:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 555/1754 [05:07<10:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 556/1754 [05:07<10:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 557/1754 [05:08<10:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 558/1754 [05:08<10:51,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 559/1754 [05:09<10:49,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 560/1754 [05:09<10:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 561/1754 [05:10<10:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 562/1754 [05:10<10:49,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 563/1754 [05:11<10:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 564/1754 [05:11<10:48,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 565/1754 [05:12<10:47,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 566/1754 [05:13<10:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 567/1754 [05:13<10:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 568/1754 [05:14<10:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 569/1754 [05:14<10:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 32%|███▏      | 570/1754 [05:15<10:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 571/1754 [05:15<10:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 572/1754 [05:16<10:43,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 573/1754 [05:16<10:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 574/1754 [05:17<10:45,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 575/1754 [05:17<10:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 576/1754 [05:18<10:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 577/1754 [05:19<10:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 578/1754 [05:19<10:40,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 579/1754 [05:20<10:39,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 580/1754 [05:20<10:38,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 581/1754 [05:21<10:37,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 582/1754 [05:21<10:36,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 583/1754 [05:22<10:36,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 584/1754 [05:22<10:37,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 585/1754 [05:23<10:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 586/1754 [05:23<10:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 33%|███▎      | 587/1754 [05:24<10:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▎      | 588/1754 [05:25<10:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▎      | 589/1754 [05:25<10:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▎      | 590/1754 [05:26<10:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▎      | 591/1754 [05:26<10:33,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 592/1754 [05:27<10:31,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 593/1754 [05:27<10:31,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 594/1754 [05:28<10:31,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 595/1754 [05:28<10:32,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 596/1754 [05:29<10:33,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 597/1754 [05:29<10:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 598/1754 [05:30<10:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 599/1754 [05:31<10:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 600/1754 [05:31<10:30,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 601/1754 [05:32<10:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 602/1754 [05:32<10:31,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 603/1754 [05:33<10:31,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 604/1754 [05:33<10:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 34%|███▍      | 605/1754 [05:34<10:27,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 35%|███▍      | 606/1754 [05:34<10:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▍      | 607/1754 [05:35<10:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▍      | 608/1754 [05:35<10:24,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▍      | 609/1754 [05:36<10:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▍      | 610/1754 [05:37<10:21,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 35%|███▍      | 611/1754 [05:37<10:21,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 35%|███▍      | 612/1754 [05:38<10:23,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 35%|███▍      | 613/1754 [05:38<10:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 614/1754 [05:39<10:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 615/1754 [05:39<10:22,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 616/1754 [05:40<10:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 617/1754 [05:40<10:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 618/1754 [05:41<10:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 619/1754 [05:41<10:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 620/1754 [05:42<10:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 621/1754 [05:43<10:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 35%|███▌      | 622/1754 [05:43<10:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 623/1754 [05:44<10:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 624/1754 [05:44<10:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 625/1754 [05:45<10:18,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 626/1754 [05:45<10:18,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 627/1754 [05:46<10:17,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 628/1754 [05:46<10:16,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 629/1754 [05:47<10:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 630/1754 [05:47<10:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 631/1754 [05:48<10:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 632/1754 [05:49<10:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 633/1754 [05:49<10:10,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 634/1754 [05:50<10:09,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▌      | 635/1754 [05:50<10:09,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▋      | 636/1754 [05:51<10:08,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▋      | 637/1754 [05:51<10:07,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▋      | 638/1754 [05:52<10:07,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 36%|███▋      | 639/1754 [05:52<10:08,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 36%|███▋      | 640/1754 [05:53<10:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 641/1754 [05:53<10:10,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 642/1754 [05:54<10:10,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 643/1754 [05:55<10:09,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 644/1754 [05:55<10:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 645/1754 [05:56<10:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 646/1754 [05:56<10:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 647/1754 [05:57<10:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 648/1754 [05:57<10:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 649/1754 [05:58<10:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 650/1754 [05:58<10:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 651/1754 [05:59<10:04,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 652/1754 [05:59<10:04,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 653/1754 [06:00<10:03,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 654/1754 [06:01<10:03,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 655/1754 [06:01<10:03,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 656/1754 [06:02<10:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 37%|███▋      | 657/1754 [06:02<10:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 658/1754 [06:03<10:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 659/1754 [06:03<10:01,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 660/1754 [06:04<09:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 661/1754 [06:04<09:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 662/1754 [06:05<09:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 663/1754 [06:05<09:55,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 664/1754 [06:06<09:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 665/1754 [06:07<09:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 666/1754 [06:07<09:52,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 667/1754 [06:08<09:50,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 668/1754 [06:08<09:49,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 669/1754 [06:09<09:50,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 670/1754 [06:09<09:50,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 671/1754 [06:10<10:12,  1.77it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 672/1754 [06:11<10:25,  1.73it/s]\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 673/1754 [06:11<10:14,  1.76it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 674/1754 [06:12<10:06,  1.78it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 38%|███▊      | 675/1754 [06:12<10:01,  1.79it/s]\u001b[A[1,0]<stderr>:\n"," 39%|███▊      | 676/1754 [06:13<09:57,  1.81it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▊      | 677/1754 [06:13<09:53,  1.81it/s]\u001b[A[1,0]<stderr>:\n"," 39%|███▊      | 678/1754 [06:14<09:52,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▊      | 679/1754 [06:14<09:50,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 680/1754 [06:16<13:10,  1.36it/s]\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 681/1754 [06:16<12:07,  1.48it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 682/1754 [06:17<11:24,  1.57it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 683/1754 [06:17<11:27,  1.56it/s]\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 684/1754 [06:18<11:44,  1.52it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 685/1754 [06:19<11:09,  1.60it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 686/1754 [06:19<10:44,  1.66it/s]\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 687/1754 [06:20<10:26,  1.70it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 688/1754 [06:20<10:12,  1.74it/s]\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 689/1754 [06:21<10:02,  1.77it/s]\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 690/1754 [06:21<09:56,  1.79it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 691/1754 [06:22<09:52,  1.80it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 39%|███▉      | 692/1754 [06:22<09:49,  1.80it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 693/1754 [06:23<09:46,  1.81it/s]\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 694/1754 [06:23<09:44,  1.81it/s]\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 695/1754 [06:24<09:41,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 696/1754 [06:25<09:39,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 697/1754 [06:25<09:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 698/1754 [06:26<09:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 699/1754 [06:26<09:35,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 700/1754 [06:27<09:34,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 40%|███▉      | 701/1754 [06:27<09:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 40%|████      | 702/1754 [06:28<09:34,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 40%|████      | 703/1754 [06:28<09:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 40%|████      | 704/1754 [06:29<09:34,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 40%|████      | 705/1754 [06:29<09:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 40%|████      | 706/1754 [06:30<09:33,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 40%|████      | 707/1754 [06:31<09:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 40%|████      | 708/1754 [06:31<09:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 40%|████      | 709/1754 [06:32<09:31,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 40%|████      | 710/1754 [06:32<09:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 711/1754 [06:33<09:30,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 41%|████      | 712/1754 [06:33<09:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 713/1754 [06:34<09:28,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 41%|████      | 714/1754 [06:34<09:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 715/1754 [06:35<09:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 716/1754 [06:35<09:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 717/1754 [06:36<09:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 718/1754 [06:37<09:24,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 719/1754 [06:37<09:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 720/1754 [06:38<09:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 721/1754 [06:38<09:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 722/1754 [06:39<09:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████      | 723/1754 [06:39<09:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████▏     | 724/1754 [06:40<09:22,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 41%|████▏     | 725/1754 [06:40<09:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████▏     | 726/1754 [06:41<09:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 41%|████▏     | 727/1754 [06:41<09:18,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 728/1754 [06:42<09:17,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 729/1754 [06:43<09:18,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 730/1754 [06:43<09:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 731/1754 [06:44<09:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 732/1754 [06:44<09:16,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 733/1754 [06:45<09:16,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 734/1754 [06:45<09:14,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 735/1754 [06:46<09:14,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 736/1754 [06:46<09:14,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 737/1754 [06:47<09:12,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 738/1754 [06:47<09:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 739/1754 [06:48<09:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 740/1754 [06:49<09:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 741/1754 [06:49<09:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 742/1754 [06:50<09:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 743/1754 [06:50<09:12,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 744/1754 [06:51<09:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 42%|████▏     | 745/1754 [06:51<09:12,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 746/1754 [06:52<09:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 747/1754 [06:52<09:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 748/1754 [06:53<09:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 749/1754 [06:53<09:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 750/1754 [06:54<09:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 751/1754 [06:55<09:05,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 752/1754 [06:55<09:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 753/1754 [06:56<09:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 754/1754 [06:56<09:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 755/1754 [06:57<09:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 756/1754 [06:57<09:03,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 757/1754 [06:58<09:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 758/1754 [06:58<09:03,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 759/1754 [06:59<09:02,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 760/1754 [06:59<09:00,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 761/1754 [07:00<09:01,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 43%|████▎     | 762/1754 [07:01<09:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▎     | 763/1754 [07:01<09:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▎     | 764/1754 [07:02<09:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 44%|████▎     | 765/1754 [07:02<09:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 44%|████▎     | 766/1754 [07:03<09:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▎     | 767/1754 [07:03<08:59,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 768/1754 [07:04<08:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 769/1754 [07:04<08:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 770/1754 [07:05<08:58,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 771/1754 [07:05<08:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 772/1754 [07:06<08:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 773/1754 [07:07<08:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 774/1754 [07:07<08:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 775/1754 [07:08<08:54,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 776/1754 [07:08<08:52,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 777/1754 [07:09<08:51,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 778/1754 [07:09<08:51,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 779/1754 [07:10<08:51,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 44%|████▍     | 780/1754 [07:10<08:50,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 781/1754 [07:11<08:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 782/1754 [07:11<08:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 783/1754 [07:12<08:51,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 784/1754 [07:13<08:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 785/1754 [07:13<08:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 786/1754 [07:14<08:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 787/1754 [07:14<08:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 788/1754 [07:15<08:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▍     | 789/1754 [07:15<08:48,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 790/1754 [07:16<08:48,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 791/1754 [07:16<08:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 792/1754 [07:17<08:45,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 793/1754 [07:17<08:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 794/1754 [07:18<08:45,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 795/1754 [07:19<08:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 796/1754 [07:19<08:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 797/1754 [07:20<08:40,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 45%|████▌     | 798/1754 [07:20<08:39,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 799/1754 [07:21<08:40,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 800/1754 [07:21<08:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 801/1754 [07:22<08:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 802/1754 [07:22<08:41,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 803/1754 [07:23<08:41,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 804/1754 [07:24<08:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 805/1754 [07:24<08:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 806/1754 [07:25<08:37,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 807/1754 [07:25<08:38,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 808/1754 [07:26<08:38,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 809/1754 [07:26<08:38,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 810/1754 [07:27<08:37,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▌     | 811/1754 [07:27<08:38,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 46%|████▋     | 812/1754 [07:28<08:38,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 46%|████▋     | 813/1754 [07:28<08:37,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▋     | 814/1754 [07:29<08:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 46%|████▋     | 815/1754 [07:30<08:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 816/1754 [07:30<08:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 817/1754 [07:31<08:31,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 818/1754 [07:31<08:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 819/1754 [07:32<08:29,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 820/1754 [07:32<08:28,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 821/1754 [07:33<08:27,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 822/1754 [07:33<08:27,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 823/1754 [07:34<08:27,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 824/1754 [07:34<08:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 825/1754 [07:35<08:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 826/1754 [07:36<08:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 827/1754 [07:36<08:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 828/1754 [07:37<08:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 829/1754 [07:37<08:24,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 830/1754 [07:38<08:24,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 831/1754 [07:38<08:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 832/1754 [07:39<08:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 47%|████▋     | 833/1754 [07:39<08:23,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 834/1754 [07:40<08:22,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 835/1754 [07:40<08:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 836/1754 [07:41<08:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 837/1754 [07:42<08:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 838/1754 [07:42<08:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 839/1754 [07:43<08:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 840/1754 [07:43<08:17,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 841/1754 [07:44<08:15,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 842/1754 [07:44<08:16,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 843/1754 [07:45<08:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 844/1754 [07:45<08:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 845/1754 [07:46<08:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 846/1754 [07:46<08:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 847/1754 [07:47<08:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 848/1754 [07:48<08:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 849/1754 [07:48<08:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 48%|████▊     | 850/1754 [07:49<08:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 49%|████▊     | 851/1754 [07:49<08:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 49%|████▊     | 852/1754 [07:50<08:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 49%|████▊     | 853/1754 [07:50<08:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 49%|████▊     | 854/1754 [07:51<08:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 49%|████▊     | 855/1754 [07:51<08:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 856/1754 [07:52<08:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 857/1754 [07:52<08:11,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 858/1754 [07:53<08:11,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 859/1754 [07:54<08:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 860/1754 [07:54<08:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 861/1754 [07:55<08:10,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 862/1754 [07:55<08:09,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 863/1754 [07:56<08:08,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 864/1754 [07:56<08:07,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 865/1754 [07:57<08:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 866/1754 [07:57<08:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 867/1754 [07:58<08:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 49%|████▉     | 868/1754 [07:58<08:05,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 50%|████▉     | 869/1754 [07:59<08:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 50%|████▉     | 870/1754 [08:00<08:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 50%|████▉     | 871/1754 [08:00<08:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 50%|████▉     | 872/1754 [08:01<08:00,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 50%|████▉     | 873/1754 [08:01<07:58,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 50%|████▉     | 874/1754 [08:02<07:59,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 50%|████▉     | 875/1754 [08:02<08:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 50%|████▉     | 876/1754 [08:03<08:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 877/1754 [08:03<08:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 878/1754 [08:04<08:47,  1.66it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 879/1754 [08:05<08:32,  1.71it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 880/1754 [08:05<08:22,  1.74it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 881/1754 [08:06<08:13,  1.77it/s]\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 882/1754 [08:06<08:09,  1.78it/s]\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 883/1754 [08:07<08:05,  1.80it/s]\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 884/1754 [08:07<08:02,  1.80it/s]\u001b[A[1,0]<stderr>:\n"," 50%|█████     | 885/1754 [08:08<07:59,  1.81it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 886/1754 [08:09<07:56,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 887/1754 [08:09<07:55,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 888/1754 [08:10<07:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 889/1754 [08:10<07:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 890/1754 [08:11<07:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 891/1754 [08:11<07:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 892/1754 [08:12<07:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 893/1754 [08:12<07:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 894/1754 [08:13<07:47,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 895/1754 [08:13<07:46,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 896/1754 [08:14<07:45,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 897/1754 [08:14<07:46,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████     | 898/1754 [08:15<07:45,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████▏    | 899/1754 [08:16<07:44,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████▏    | 900/1754 [08:16<07:43,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 51%|█████▏    | 901/1754 [08:17<07:43,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 51%|█████▏    | 902/1754 [08:17<07:43,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 51%|█████▏    | 903/1754 [08:18<07:42,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 904/1754 [08:18<07:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 905/1754 [08:19<07:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 906/1754 [08:19<07:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 907/1754 [08:20<07:42,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 908/1754 [08:21<07:44,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 909/1754 [08:21<07:43,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 910/1754 [08:22<07:42,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 911/1754 [08:22<07:42,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 912/1754 [08:23<07:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 913/1754 [08:23<07:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 914/1754 [08:24<07:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 915/1754 [08:24<07:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 916/1754 [08:25<07:38,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 917/1754 [08:25<07:37,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 918/1754 [08:26<07:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 919/1754 [08:27<07:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 52%|█████▏    | 920/1754 [08:27<07:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 921/1754 [08:28<07:33,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 922/1754 [08:28<07:33,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 923/1754 [08:29<07:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 924/1754 [08:29<07:31,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 925/1754 [08:30<07:31,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 926/1754 [08:30<07:31,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 927/1754 [08:31<07:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 928/1754 [08:31<07:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 929/1754 [08:32<07:30,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 930/1754 [08:33<07:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 931/1754 [08:33<07:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 932/1754 [08:34<07:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 933/1754 [08:34<07:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 934/1754 [08:35<07:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 935/1754 [08:35<07:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 936/1754 [08:36<07:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 937/1754 [08:36<07:25,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 53%|█████▎    | 938/1754 [08:37<07:25,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 54%|█████▎    | 939/1754 [08:37<07:24,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 54%|█████▎    | 940/1754 [08:38<07:24,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 54%|█████▎    | 941/1754 [08:39<07:25,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▎    | 942/1754 [08:39<07:25,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 943/1754 [08:40<07:23,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 944/1754 [08:40<07:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 945/1754 [08:41<07:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 946/1754 [08:41<07:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 947/1754 [08:42<07:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 948/1754 [08:42<07:20,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 949/1754 [08:43<07:19,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 950/1754 [08:43<07:19,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 951/1754 [08:44<07:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 952/1754 [08:45<07:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 953/1754 [08:45<07:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 954/1754 [08:46<07:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 54%|█████▍    | 955/1754 [08:46<07:16,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 956/1754 [08:47<07:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 957/1754 [08:47<07:16,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 958/1754 [08:48<07:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 959/1754 [08:48<07:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 960/1754 [08:49<07:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 961/1754 [08:49<07:14,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 962/1754 [08:50<07:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 963/1754 [08:51<07:12,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 55%|█████▍    | 964/1754 [08:51<07:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 965/1754 [08:52<07:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 966/1754 [08:52<07:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 967/1754 [08:53<07:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 968/1754 [08:53<07:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 969/1754 [08:54<07:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 970/1754 [08:54<07:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 971/1754 [08:55<07:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 972/1754 [08:55<07:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 55%|█████▌    | 973/1754 [08:56<07:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 974/1754 [08:57<07:08,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 975/1754 [08:57<07:07,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 976/1754 [08:58<07:06,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 977/1754 [08:58<07:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 978/1754 [08:59<07:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 979/1754 [08:59<07:03,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 980/1754 [09:00<07:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 981/1754 [09:00<07:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 982/1754 [09:01<07:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 983/1754 [09:01<07:00,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 984/1754 [09:02<06:59,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 985/1754 [09:03<06:59,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▌    | 986/1754 [09:03<06:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▋    | 987/1754 [09:04<06:57,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▋    | 988/1754 [09:04<06:57,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▋    | 989/1754 [09:05<06:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▋    | 990/1754 [09:05<06:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 56%|█████▋    | 991/1754 [09:06<06:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 992/1754 [09:06<06:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 993/1754 [09:07<06:56,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 994/1754 [09:07<06:56,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 995/1754 [09:08<06:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 996/1754 [09:09<06:55,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 997/1754 [09:09<06:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 998/1754 [09:10<06:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 999/1754 [09:10<06:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1000/1754 [09:11<06:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1001/1754 [09:11<06:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1002/1754 [09:12<06:52,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1003/1754 [09:12<06:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1004/1754 [09:13<06:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1005/1754 [09:14<06:47,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1006/1754 [09:14<06:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1007/1754 [09:15<06:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 57%|█████▋    | 1008/1754 [09:15<06:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1009/1754 [09:16<06:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1010/1754 [09:16<06:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1011/1754 [09:17<06:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1012/1754 [09:17<06:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1013/1754 [09:18<06:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1014/1754 [09:18<06:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1015/1754 [09:19<06:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1016/1754 [09:20<06:41,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1017/1754 [09:20<06:41,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1018/1754 [09:21<06:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1019/1754 [09:21<06:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1020/1754 [09:22<06:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1021/1754 [09:22<06:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1022/1754 [09:23<06:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1023/1754 [09:23<06:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1024/1754 [09:24<06:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1025/1754 [09:24<06:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 58%|█████▊    | 1026/1754 [09:25<06:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▊    | 1027/1754 [09:26<06:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▊    | 1028/1754 [09:26<06:35,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▊    | 1029/1754 [09:27<06:34,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▊    | 1030/1754 [09:27<06:34,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1031/1754 [09:28<06:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1032/1754 [09:28<06:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1033/1754 [09:29<06:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1034/1754 [09:29<06:32,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1035/1754 [09:30<06:31,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1036/1754 [09:30<06:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1037/1754 [09:31<06:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1038/1754 [09:32<06:29,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1039/1754 [09:32<06:30,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1040/1754 [09:33<06:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1041/1754 [09:33<06:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1042/1754 [09:34<06:29,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 59%|█████▉    | 1043/1754 [09:34<06:28,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1044/1754 [09:35<06:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1045/1754 [09:35<06:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1046/1754 [09:36<06:26,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1047/1754 [09:36<06:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1048/1754 [09:37<06:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1049/1754 [09:38<06:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1050/1754 [09:38<06:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1051/1754 [09:39<06:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|█████▉    | 1052/1754 [09:39<06:25,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1053/1754 [09:40<06:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1054/1754 [09:40<06:22,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1055/1754 [09:41<06:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1056/1754 [09:41<06:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1057/1754 [09:42<06:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1058/1754 [09:42<06:20,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1059/1754 [09:43<06:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1060/1754 [09:44<06:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 60%|██████    | 1061/1754 [09:44<06:17,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1062/1754 [09:45<06:16,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1063/1754 [09:45<06:17,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1064/1754 [09:46<06:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1065/1754 [09:46<06:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1066/1754 [09:47<06:14,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1067/1754 [09:47<06:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1068/1754 [09:48<06:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1069/1754 [09:48<06:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1070/1754 [09:49<06:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1071/1754 [09:50<06:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1072/1754 [09:50<06:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1073/1754 [09:51<06:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 61%|██████    | 1074/1754 [09:51<06:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 61%|██████▏   | 1075/1754 [09:52<06:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████▏   | 1076/1754 [09:52<06:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 61%|██████▏   | 1077/1754 [09:53<06:08,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 61%|██████▏   | 1078/1754 [09:53<06:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1079/1754 [09:54<06:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1080/1754 [09:54<06:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1081/1754 [09:55<06:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1082/1754 [09:56<06:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1083/1754 [09:56<06:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1084/1754 [09:57<06:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1085/1754 [09:57<06:07,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1086/1754 [09:58<06:06,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1087/1754 [09:58<06:05,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1088/1754 [09:59<06:04,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1089/1754 [09:59<06:03,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1090/1754 [10:00<06:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1091/1754 [10:00<06:01,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1092/1754 [10:01<06:01,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1093/1754 [10:02<06:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1094/1754 [10:02<06:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1095/1754 [10:03<06:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 62%|██████▏   | 1096/1754 [10:03<06:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1097/1754 [10:04<05:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1098/1754 [10:04<05:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1099/1754 [10:05<05:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1100/1754 [10:05<05:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1101/1754 [10:06<05:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1102/1754 [10:06<05:55,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1103/1754 [10:07<05:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1104/1754 [10:08<05:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1105/1754 [10:08<05:54,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1106/1754 [10:09<05:54,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1107/1754 [10:09<05:55,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1108/1754 [10:10<05:54,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1109/1754 [10:10<05:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1110/1754 [10:11<05:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1111/1754 [10:11<05:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1112/1754 [10:12<05:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 63%|██████▎   | 1113/1754 [10:13<05:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 64%|██████▎   | 1114/1754 [10:13<05:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▎   | 1115/1754 [10:14<05:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▎   | 1116/1754 [10:14<05:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▎   | 1117/1754 [10:15<05:46,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 64%|██████▎   | 1118/1754 [10:15<05:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1119/1754 [10:16<05:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1120/1754 [10:16<05:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1121/1754 [10:17<05:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1122/1754 [10:17<05:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1123/1754 [10:18<05:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1124/1754 [10:19<05:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1125/1754 [10:19<05:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1126/1754 [10:20<05:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1127/1754 [10:20<05:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1128/1754 [10:21<05:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1129/1754 [10:21<05:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1130/1754 [10:22<05:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 64%|██████▍   | 1131/1754 [10:22<05:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1132/1754 [10:23<05:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1133/1754 [10:23<05:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1134/1754 [10:24<05:37,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1135/1754 [10:25<05:36,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1136/1754 [10:25<05:35,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1137/1754 [10:26<05:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1138/1754 [10:26<05:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1139/1754 [10:27<05:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▍   | 1140/1754 [10:27<05:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▌   | 1141/1754 [10:28<05:37,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 65%|██████▌   | 1142/1754 [10:28<05:36,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 65%|██████▌   | 1143/1754 [10:29<05:35,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▌   | 1144/1754 [10:29<05:34,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 65%|██████▌   | 1145/1754 [10:30<05:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▌   | 1146/1754 [10:31<05:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▌   | 1147/1754 [10:31<05:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 65%|██████▌   | 1148/1754 [10:32<05:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1149/1754 [10:32<05:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1150/1754 [10:33<05:30,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1151/1754 [10:33<05:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1152/1754 [10:34<05:29,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1153/1754 [10:34<05:29,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1154/1754 [10:35<05:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1155/1754 [10:35<05:27,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1156/1754 [10:36<05:27,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1157/1754 [10:37<05:27,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1158/1754 [10:37<05:26,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1159/1754 [10:38<05:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1160/1754 [10:38<05:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1161/1754 [10:39<05:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▌   | 1162/1754 [10:39<05:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▋   | 1163/1754 [10:40<05:22,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 66%|██████▋   | 1164/1754 [10:40<05:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▋   | 1165/1754 [10:41<05:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 66%|██████▋   | 1166/1754 [10:41<05:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1167/1754 [10:42<05:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1168/1754 [10:43<05:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1169/1754 [10:43<05:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1170/1754 [10:44<05:18,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1171/1754 [10:44<05:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1172/1754 [10:45<05:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1173/1754 [10:45<05:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1174/1754 [10:46<05:15,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1175/1754 [10:46<05:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1176/1754 [10:47<05:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1177/1754 [10:47<05:14,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1178/1754 [10:48<05:13,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1179/1754 [10:49<05:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1180/1754 [10:49<05:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1181/1754 [10:50<05:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1182/1754 [10:50<05:11,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 67%|██████▋   | 1183/1754 [10:51<05:10,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1184/1754 [10:51<05:11,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1185/1754 [10:52<05:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1186/1754 [10:52<05:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1187/1754 [10:53<05:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1188/1754 [10:53<05:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1189/1754 [10:54<05:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1190/1754 [10:55<05:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1191/1754 [10:55<05:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1192/1754 [10:56<05:07,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1193/1754 [10:56<05:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1194/1754 [10:57<05:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1195/1754 [10:57<05:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1196/1754 [10:58<05:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1197/1754 [10:58<05:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1198/1754 [10:59<05:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1199/1754 [11:00<05:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1200/1754 [11:00<05:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 68%|██████▊   | 1201/1754 [11:01<05:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 69%|██████▊   | 1202/1754 [11:01<05:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▊   | 1203/1754 [11:02<05:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 69%|██████▊   | 1204/1754 [11:02<04:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▊   | 1205/1754 [11:03<04:59,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1206/1754 [11:03<04:58,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1207/1754 [11:04<04:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1208/1754 [11:04<04:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1209/1754 [11:05<04:57,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1210/1754 [11:06<04:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1211/1754 [11:06<04:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1212/1754 [11:07<04:55,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1213/1754 [11:07<04:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1214/1754 [11:08<04:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1215/1754 [11:08<04:53,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1216/1754 [11:09<04:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1217/1754 [11:09<04:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1218/1754 [11:10<04:52,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 69%|██████▉   | 1219/1754 [11:10<04:52,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 70%|██████▉   | 1220/1754 [11:11<04:52,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 70%|██████▉   | 1221/1754 [11:12<04:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 70%|██████▉   | 1222/1754 [11:12<04:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 70%|██████▉   | 1223/1754 [11:13<04:49,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 70%|██████▉   | 1224/1754 [11:13<04:49,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 70%|██████▉   | 1225/1754 [11:14<04:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|██████▉   | 1226/1754 [11:14<04:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|██████▉   | 1227/1754 [11:15<04:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1228/1754 [11:15<04:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1229/1754 [11:16<04:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1230/1754 [11:16<04:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1231/1754 [11:17<04:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1232/1754 [11:18<04:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1233/1754 [11:18<04:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1234/1754 [11:19<04:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1235/1754 [11:19<04:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 70%|███████   | 1236/1754 [11:20<04:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1237/1754 [11:20<04:42,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1238/1754 [11:21<04:42,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1239/1754 [11:21<04:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1240/1754 [11:22<04:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1241/1754 [11:22<04:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1242/1754 [11:23<04:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1243/1754 [11:24<04:38,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1244/1754 [11:24<04:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1245/1754 [11:25<04:37,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1246/1754 [11:25<04:36,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1247/1754 [11:26<04:35,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1248/1754 [11:26<04:35,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████   | 1249/1754 [11:27<04:34,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████▏  | 1250/1754 [11:27<04:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████▏  | 1251/1754 [11:28<04:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 71%|███████▏  | 1252/1754 [11:28<04:33,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 71%|███████▏  | 1253/1754 [11:29<04:33,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 71%|███████▏  | 1254/1754 [11:30<04:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1255/1754 [11:30<04:32,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1256/1754 [11:31<04:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1257/1754 [11:31<04:30,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1258/1754 [11:32<04:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1259/1754 [11:32<04:29,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1260/1754 [11:33<04:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1261/1754 [11:33<04:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1262/1754 [11:34<04:28,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1263/1754 [11:34<04:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1264/1754 [11:35<04:26,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1265/1754 [11:36<04:25,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1266/1754 [11:36<04:24,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1267/1754 [11:37<04:24,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1268/1754 [11:37<04:24,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1269/1754 [11:38<04:24,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1270/1754 [11:38<04:23,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 72%|███████▏  | 1271/1754 [11:39<04:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1272/1754 [11:39<04:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1273/1754 [11:40<04:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1274/1754 [11:40<04:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1275/1754 [11:41<04:20,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1276/1754 [11:42<04:21,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1277/1754 [11:42<04:21,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1278/1754 [11:43<04:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1279/1754 [11:43<04:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1280/1754 [11:44<04:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1281/1754 [11:44<04:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1282/1754 [11:45<04:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1283/1754 [11:45<04:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1284/1754 [11:46<04:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1285/1754 [11:46<04:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1286/1754 [11:47<04:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1287/1754 [11:48<04:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1288/1754 [11:48<04:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 73%|███████▎  | 1289/1754 [11:49<04:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▎  | 1290/1754 [11:49<04:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 74%|███████▎  | 1291/1754 [11:50<04:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 74%|███████▎  | 1292/1754 [11:50<04:13,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 74%|███████▎  | 1293/1754 [11:51<04:12,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1294/1754 [11:51<04:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1295/1754 [11:52<04:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1296/1754 [11:52<04:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1297/1754 [11:53<04:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1298/1754 [11:54<04:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1299/1754 [11:54<04:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1300/1754 [11:55<04:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1301/1754 [11:55<04:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1302/1754 [11:56<04:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1303/1754 [11:56<04:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1304/1754 [11:57<04:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1305/1754 [11:57<04:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 74%|███████▍  | 1306/1754 [11:58<04:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1307/1754 [11:58<04:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1308/1754 [11:59<04:03,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1309/1754 [12:00<04:03,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1310/1754 [12:00<04:03,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1311/1754 [12:01<04:02,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1312/1754 [12:01<04:02,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1313/1754 [12:02<04:01,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1314/1754 [12:02<04:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▍  | 1315/1754 [12:03<03:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1316/1754 [12:03<03:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1317/1754 [12:04<03:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1318/1754 [12:04<03:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1319/1754 [12:05<03:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1320/1754 [12:06<03:56,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1321/1754 [12:06<03:56,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1322/1754 [12:07<03:57,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1323/1754 [12:07<03:56,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 75%|███████▌  | 1324/1754 [12:08<03:55,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1325/1754 [12:08<03:55,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1326/1754 [12:09<03:55,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1327/1754 [12:09<03:54,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1328/1754 [12:10<03:54,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1329/1754 [12:11<03:53,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1330/1754 [12:11<03:52,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1331/1754 [12:12<03:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1332/1754 [12:12<03:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1333/1754 [12:13<03:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1334/1754 [12:13<03:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1335/1754 [12:14<03:49,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1336/1754 [12:14<03:49,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 76%|███████▌  | 1337/1754 [12:15<03:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▋  | 1338/1754 [12:15<03:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▋  | 1339/1754 [12:16<03:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▋  | 1340/1754 [12:17<03:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 76%|███████▋  | 1341/1754 [12:17<03:46,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1342/1754 [12:18<03:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1343/1754 [12:18<03:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1344/1754 [12:19<03:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1345/1754 [12:19<03:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1346/1754 [12:20<03:44,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1347/1754 [12:20<03:44,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1348/1754 [12:21<03:43,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1349/1754 [12:21<03:43,  1.81it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1350/1754 [12:22<03:42,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1351/1754 [12:23<03:41,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1352/1754 [12:23<03:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1353/1754 [12:24<03:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1354/1754 [12:24<03:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1355/1754 [12:25<03:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1356/1754 [12:25<03:37,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1357/1754 [12:26<03:37,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1358/1754 [12:26<03:37,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 77%|███████▋  | 1359/1754 [12:27<03:36,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1360/1754 [12:27<03:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1361/1754 [12:28<03:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1362/1754 [12:29<03:34,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1363/1754 [12:29<03:34,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1364/1754 [12:30<03:34,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1365/1754 [12:30<03:33,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1366/1754 [12:31<03:33,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1367/1754 [12:31<03:32,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1368/1754 [12:32<03:31,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1369/1754 [12:32<03:31,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1370/1754 [12:33<03:30,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1371/1754 [12:34<03:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1372/1754 [12:34<03:28,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1373/1754 [12:35<03:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1374/1754 [12:35<03:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1375/1754 [12:36<03:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 78%|███████▊  | 1376/1754 [12:36<03:25,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 79%|███████▊  | 1377/1754 [12:37<03:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▊  | 1378/1754 [12:37<03:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▊  | 1379/1754 [12:38<03:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▊  | 1380/1754 [12:38<03:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▊  | 1381/1754 [12:39<03:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1382/1754 [12:40<03:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1383/1754 [12:40<03:22,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1384/1754 [12:41<03:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1385/1754 [12:41<03:21,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1386/1754 [12:42<03:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1387/1754 [12:42<03:21,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1388/1754 [12:43<03:20,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1389/1754 [12:43<03:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1390/1754 [12:44<03:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1391/1754 [12:44<03:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1392/1754 [12:45<03:17,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1393/1754 [12:46<03:17,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 79%|███████▉  | 1394/1754 [12:46<03:16,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1395/1754 [12:47<03:16,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1396/1754 [12:47<03:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1397/1754 [12:48<03:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1398/1754 [12:48<03:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1399/1754 [12:49<03:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1400/1754 [12:49<03:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1401/1754 [12:50<03:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1402/1754 [12:50<03:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 80%|███████▉  | 1403/1754 [12:51<03:12,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 80%|████████  | 1404/1754 [12:52<03:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 80%|████████  | 1405/1754 [12:52<03:38,  1.59it/s]\u001b[A[1,0]<stderr>:\n"," 80%|████████  | 1406/1754 [12:53<03:29,  1.66it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 80%|████████  | 1407/1754 [12:53<03:22,  1.71it/s]\u001b[A[1,0]<stderr>:\n"," 80%|████████  | 1408/1754 [12:54<03:18,  1.74it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 80%|████████  | 1409/1754 [12:55<04:38,  1.24it/s]\u001b[A[1,0]<stderr>:\n"," 80%|████████  | 1410/1754 [12:56<04:11,  1.37it/s]\u001b[A[1,0]<stderr>:\n"," 80%|████████  | 1411/1754 [12:56<03:51,  1.48it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1412/1754 [12:57<03:37,  1.57it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1413/1754 [12:58<03:27,  1.64it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1414/1754 [12:58<03:20,  1.69it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1415/1754 [12:59<03:15,  1.74it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1416/1754 [12:59<03:11,  1.77it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1417/1754 [13:00<03:08,  1.78it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1418/1754 [13:00<03:07,  1.80it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1419/1754 [13:01<03:04,  1.81it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1420/1754 [13:01<03:03,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1421/1754 [13:02<03:03,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1422/1754 [13:02<03:02,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1423/1754 [13:03<03:01,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1424/1754 [13:04<03:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 81%|████████  | 1425/1754 [13:04<03:00,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 81%|████████▏ | 1426/1754 [13:05<02:59,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 81%|████████▏ | 1427/1754 [13:05<02:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 81%|████████▏ | 1428/1754 [13:06<02:58,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 81%|████████▏ | 1429/1754 [13:06<02:57,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1430/1754 [13:07<02:57,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1431/1754 [13:07<02:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1432/1754 [13:08<02:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1433/1754 [13:08<02:55,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1434/1754 [13:09<02:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1435/1754 [13:10<02:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1436/1754 [13:10<02:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1437/1754 [13:11<02:53,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1438/1754 [13:11<02:52,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1439/1754 [13:12<02:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1440/1754 [13:12<02:51,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1441/1754 [13:13<02:51,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1442/1754 [13:13<02:50,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1443/1754 [13:14<02:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1444/1754 [13:14<02:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1445/1754 [13:15<02:49,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1446/1754 [13:16<02:48,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 82%|████████▏ | 1447/1754 [13:16<02:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1448/1754 [13:17<02:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1449/1754 [13:17<02:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1450/1754 [13:18<02:46,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1451/1754 [13:18<02:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1452/1754 [13:19<02:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1453/1754 [13:19<02:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1454/1754 [13:20<02:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1455/1754 [13:21<02:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1456/1754 [13:21<02:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1457/1754 [13:22<02:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1458/1754 [13:22<02:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1459/1754 [13:23<02:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1460/1754 [13:23<02:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1461/1754 [13:24<02:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1462/1754 [13:24<02:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1463/1754 [13:25<02:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 83%|████████▎ | 1464/1754 [13:25<02:38,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 84%|████████▎ | 1465/1754 [13:26<02:38,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▎ | 1466/1754 [13:27<02:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▎ | 1467/1754 [13:27<02:36,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 84%|████████▎ | 1468/1754 [13:28<02:36,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1469/1754 [13:28<02:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1470/1754 [13:29<02:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1471/1754 [13:29<02:34,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1472/1754 [13:30<02:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1473/1754 [13:30<02:33,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1474/1754 [13:31<02:33,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1475/1754 [13:31<02:32,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1476/1754 [13:32<02:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1477/1754 [13:33<02:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1478/1754 [13:33<02:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1479/1754 [13:34<02:29,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1480/1754 [13:34<02:29,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1481/1754 [13:35<02:28,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 84%|████████▍ | 1482/1754 [13:35<02:27,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 85%|████████▍ | 1483/1754 [13:36<02:27,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▍ | 1484/1754 [13:36<02:26,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▍ | 1485/1754 [13:37<02:26,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▍ | 1486/1754 [13:37<02:25,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▍ | 1487/1754 [13:38<02:25,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▍ | 1488/1754 [13:39<02:24,  1.85it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▍ | 1489/1754 [13:39<02:23,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▍ | 1490/1754 [13:40<02:22,  1.85it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1491/1754 [13:40<02:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1492/1754 [13:41<02:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1493/1754 [13:41<02:21,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1494/1754 [13:42<02:21,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1495/1754 [13:42<02:21,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1496/1754 [13:43<02:20,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1497/1754 [13:43<02:19,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1498/1754 [13:44<02:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 85%|████████▌ | 1499/1754 [13:44<02:18,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1500/1754 [13:45<02:18,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1501/1754 [13:46<02:17,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1502/1754 [13:46<02:16,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1503/1754 [13:47<02:16,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1504/1754 [13:47<02:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1505/1754 [13:48<02:15,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1506/1754 [13:48<02:15,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1507/1754 [13:49<02:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1508/1754 [13:49<02:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1509/1754 [13:50<02:13,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1510/1754 [13:50<02:12,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1511/1754 [13:51<02:12,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 86%|████████▌ | 1512/1754 [13:52<02:12,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 86%|████████▋ | 1513/1754 [13:52<02:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▋ | 1514/1754 [13:53<02:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▋ | 1515/1754 [13:53<02:10,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 86%|████████▋ | 1516/1754 [13:54<02:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 86%|████████▋ | 1517/1754 [13:54<02:09,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1518/1754 [13:55<02:09,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1519/1754 [13:55<02:08,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1520/1754 [13:56<02:08,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1521/1754 [13:57<02:07,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1522/1754 [13:57<02:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1523/1754 [13:58<02:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1524/1754 [13:58<02:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1525/1754 [13:59<02:05,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1526/1754 [13:59<02:04,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1527/1754 [14:00<02:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1528/1754 [14:00<02:04,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1529/1754 [14:01<02:03,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1530/1754 [14:01<02:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1531/1754 [14:02<02:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1532/1754 [14:03<02:01,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1533/1754 [14:03<02:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 87%|████████▋ | 1534/1754 [14:04<02:00,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1535/1754 [14:04<01:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1536/1754 [14:05<01:59,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1537/1754 [14:05<01:58,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1538/1754 [14:06<01:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1539/1754 [14:06<01:57,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1540/1754 [14:07<01:57,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1541/1754 [14:07<01:56,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1542/1754 [14:08<01:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1543/1754 [14:09<01:55,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1544/1754 [14:09<01:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1545/1754 [14:10<01:54,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1546/1754 [14:10<01:53,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1547/1754 [14:11<01:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1548/1754 [14:11<01:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1549/1754 [14:12<01:51,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1550/1754 [14:12<01:51,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1551/1754 [14:13<01:50,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 88%|████████▊ | 1552/1754 [14:13<01:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▊ | 1553/1754 [14:14<01:49,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 89%|████████▊ | 1554/1754 [14:15<01:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▊ | 1555/1754 [14:15<01:48,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 89%|████████▊ | 1556/1754 [14:16<01:48,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1557/1754 [14:16<01:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1558/1754 [14:17<01:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1559/1754 [14:17<01:46,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1560/1754 [14:18<01:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1561/1754 [14:18<01:45,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1562/1754 [14:19<01:44,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1563/1754 [14:19<01:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1564/1754 [14:20<01:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1565/1754 [14:21<01:43,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1566/1754 [14:21<01:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1567/1754 [14:22<01:41,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1568/1754 [14:22<01:41,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 89%|████████▉ | 1569/1754 [14:23<01:40,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1570/1754 [14:23<01:40,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1571/1754 [14:24<01:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1572/1754 [14:24<01:39,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1573/1754 [14:25<01:38,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1574/1754 [14:25<01:37,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1575/1754 [14:26<01:37,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1576/1754 [14:27<01:37,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1577/1754 [14:27<01:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 90%|████████▉ | 1578/1754 [14:28<01:36,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1579/1754 [14:28<01:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1580/1754 [14:29<01:35,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1581/1754 [14:29<01:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1582/1754 [14:30<01:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1583/1754 [14:30<01:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1584/1754 [14:31<01:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1585/1754 [14:31<01:32,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1586/1754 [14:32<01:32,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 90%|█████████ | 1587/1754 [14:33<01:31,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1588/1754 [14:33<01:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1589/1754 [14:34<01:30,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1590/1754 [14:34<01:29,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1591/1754 [14:35<01:29,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1592/1754 [14:35<01:28,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1593/1754 [14:36<01:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1594/1754 [14:36<01:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1595/1754 [14:37<01:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1596/1754 [14:37<01:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1597/1754 [14:38<01:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1598/1754 [14:39<01:24,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1599/1754 [14:39<01:24,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████ | 1600/1754 [14:40<01:23,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 91%|█████████▏| 1601/1754 [14:40<01:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████▏| 1602/1754 [14:41<01:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████▏| 1603/1754 [14:41<01:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 91%|█████████▏| 1604/1754 [14:42<01:21,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1605/1754 [14:42<01:21,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1606/1754 [14:43<01:20,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1607/1754 [14:44<01:20,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1608/1754 [14:44<01:19,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1609/1754 [14:45<01:19,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1610/1754 [14:45<01:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1611/1754 [14:46<01:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1612/1754 [14:46<01:17,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1613/1754 [14:47<01:17,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1614/1754 [14:47<01:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1615/1754 [14:48<01:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1616/1754 [14:48<01:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1617/1754 [14:49<01:14,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1618/1754 [14:50<01:14,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1619/1754 [14:50<01:14,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1620/1754 [14:51<01:13,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1621/1754 [14:51<01:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 92%|█████████▏| 1622/1754 [14:52<01:12,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1623/1754 [14:52<01:11,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1624/1754 [14:53<01:11,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1625/1754 [14:53<01:10,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1626/1754 [14:54<01:10,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1627/1754 [14:54<01:09,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1628/1754 [14:55<01:08,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1629/1754 [14:56<01:08,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1630/1754 [14:56<01:07,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1631/1754 [14:57<01:07,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1632/1754 [14:57<01:06,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1633/1754 [14:58<01:06,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1634/1754 [14:58<01:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1635/1754 [14:59<01:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1636/1754 [14:59<01:04,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1637/1754 [15:00<01:03,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1638/1754 [15:00<01:03,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 93%|█████████▎| 1639/1754 [15:01<01:02,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 94%|█████████▎| 1640/1754 [15:02<01:02,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▎| 1641/1754 [15:02<01:01,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 94%|█████████▎| 1642/1754 [15:03<01:01,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 94%|█████████▎| 1643/1754 [15:03<01:00,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▎| 1644/1754 [15:04<01:00,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1645/1754 [15:04<00:59,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1646/1754 [15:05<00:59,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1647/1754 [15:05<00:58,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1648/1754 [15:06<00:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1649/1754 [15:06<00:57,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1650/1754 [15:07<00:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1651/1754 [15:08<00:56,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1652/1754 [15:08<00:55,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1653/1754 [15:09<00:55,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1654/1754 [15:09<00:54,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1655/1754 [15:10<00:53,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1656/1754 [15:10<00:53,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 94%|█████████▍| 1657/1754 [15:11<00:52,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1658/1754 [15:11<00:52,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1659/1754 [15:12<00:52,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1660/1754 [15:12<00:51,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1661/1754 [15:13<00:50,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1662/1754 [15:14<00:50,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1663/1754 [15:14<00:49,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1664/1754 [15:15<00:49,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1665/1754 [15:15<00:48,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▍| 1666/1754 [15:16<00:47,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1667/1754 [15:16<00:47,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1668/1754 [15:17<00:47,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1669/1754 [15:17<00:46,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1670/1754 [15:18<00:46,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1671/1754 [15:19<00:45,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1672/1754 [15:19<00:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1673/1754 [15:20<00:44,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1674/1754 [15:20<00:43,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 95%|█████████▌| 1675/1754 [15:21<00:43,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1676/1754 [15:21<00:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1677/1754 [15:22<00:42,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1678/1754 [15:22<00:41,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1679/1754 [15:23<00:40,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1680/1754 [15:23<00:40,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1681/1754 [15:24<00:39,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1682/1754 [15:25<00:39,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1683/1754 [15:25<00:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1684/1754 [15:26<00:38,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1685/1754 [15:26<00:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1686/1754 [15:27<00:37,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1687/1754 [15:27<00:36,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▌| 1688/1754 [15:28<00:35,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▋| 1689/1754 [15:28<00:35,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▋| 1690/1754 [15:29<00:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▋| 1691/1754 [15:29<00:34,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 96%|█████████▋| 1692/1754 [15:30<00:33,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1693/1754 [15:31<00:33,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1694/1754 [15:31<00:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1695/1754 [15:32<00:32,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1696/1754 [15:32<00:31,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1697/1754 [15:33<00:30,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1698/1754 [15:33<00:30,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1699/1754 [15:34<00:29,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1700/1754 [15:34<00:29,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1701/1754 [15:35<00:29,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1702/1754 [15:35<00:28,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1703/1754 [15:36<00:27,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1704/1754 [15:37<00:27,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1705/1754 [15:37<00:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1706/1754 [15:38<00:26,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1707/1754 [15:38<00:25,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1708/1754 [15:39<00:25,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1709/1754 [15:39<00:24,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 97%|█████████▋| 1710/1754 [15:40<00:24,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1711/1754 [15:40<00:23,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1712/1754 [15:41<00:22,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1713/1754 [15:41<00:22,  1.84it/s]\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1714/1754 [15:42<00:21,  1.84it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1715/1754 [15:43<00:21,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1716/1754 [15:43<00:20,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1717/1754 [15:44<00:20,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1718/1754 [15:44<00:19,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1719/1754 [15:45<00:19,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1720/1754 [15:45<00:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1721/1754 [15:46<00:18,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1722/1754 [15:46<00:17,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1723/1754 [15:47<00:16,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1724/1754 [15:47<00:16,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1725/1754 [15:48<00:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1726/1754 [15:49<00:15,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 98%|█████████▊| 1727/1754 [15:49<00:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▊| 1728/1754 [15:50<00:14,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▊| 1729/1754 [15:50<00:13,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▊| 1730/1754 [15:51<00:13,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 99%|█████████▊| 1731/1754 [15:51<00:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▊| 1732/1754 [15:52<00:12,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1733/1754 [15:52<00:11,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1734/1754 [15:53<00:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1735/1754 [15:53<00:10,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1736/1754 [15:54<00:09,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1737/1754 [15:55<00:09,  1.82it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1738/1754 [15:55<00:08,  1.82it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1739/1754 [15:56<00:08,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1740/1754 [15:56<00:07,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1741/1754 [15:57<00:07,  1.83it/s][1,0]<stderr>:\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1742/1754 [15:57<00:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1743/1754 [15:58<00:06,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1744/1754 [15:58<00:05,  1.83it/s]\u001b[A[1,0]<stderr>:\n"," 99%|█████████▉| 1745/1754 [15:59<00:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n","100%|█████████▉| 1746/1754 [15:59<00:04,  1.83it/s]\u001b[A[1,0]<stderr>:\n","100%|█████████▉| 1747/1754 [16:00<00:03,  1.84it/s]\u001b[A[1,0]<stderr>:\n","100%|█████████▉| 1748/1754 [16:01<00:03,  1.84it/s]\u001b[A[1,0]<stderr>:\n","100%|█████████▉| 1749/1754 [16:01<00:02,  1.84it/s]\u001b[A[1,0]<stderr>:\n","100%|█████████▉| 1750/1754 [16:02<00:02,  1.84it/s]\u001b[A[1,0]<stderr>:\n","100%|█████████▉| 1751/1754 [16:02<00:01,  1.84it/s]\u001b[A[1,0]<stderr>:\n","100%|█████████▉| 1752/1754 [16:03<00:01,  1.84it/s]\u001b[A[1,0]<stderr>:\n","100%|█████████▉| 1753/1754 [16:03<00:00,  1.84it/s]\u001b[A[1,0]<stderr>:\n","100%|██████████| 1754/1754 [16:04<00:00,  1.78it/s]\u001b[A[1,0]<stderr>:06/21/2022 01:50:49 - INFO - __main__ -   QA Task [msrvtt_qa], 12278 qa_results,3 examples here: [{'question_id': 0, 'answer': 314, 'data': {'question': 'what are three people sitting on?', 'vid_id': 'video6513', 'answer': 'couch', 'question_id': 0, 'answer_type': 'what'}}, {'question_id': 1, 'answer': 305, 'data': {'question': 'what is a family having?', 'vid_id': 'video6513', 'answer': 'coversation', 'question_id': 1, 'answer_type': 'what'}}, {'question_id': 2, 'answer': 855, 'data': {'question': 'what plays?', 'vid_id': 'video6513', 'answer': 'music', 'question_id': 2, 'answer_type': 'what'}}]\n","[1,0]<stderr>:06/21/2022 01:50:49 - INFO - __main__ -   validation finished in 964 seconds.{'ratios': {'what_ratio': [67.9, 8337], 'who_ratio': [28.01, 3439], 'how_ratio': [2.8, 344], 'where_ratio': [0.42, 52], 'when_ratio': [0.86, 106]}, 'overall_acc': 38.95, 'what_acc': 32.35, 'who_acc': 49.52, 'how_acc': 81.69, 'where_acc': 40.38, 'when_acc': 75.47}\n","100%|██████████| 1754/1754 [16:04<00:00,  1.82it/s][1,0]<stderr>:\n","[1,0]<stderr>:06/21/2022 01:50:50 - INFO - __main__ -   ModelSaver save trial NO. 0\n"," 17%|█▋        | 4521/26621 [1:31:31<105:15:26, 17.15s/it][1,0]<stderr>:06/21/2022 02:25:34 - INFO - __main__ -   TrainingRestorer save trial NO. 0\n"," 18%|█▊        | 4731/26621 [2:31:15<103:27:58, 17.02s/it]"]}]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"ALPRO(Testing).ipynb","provenance":[],"mount_file_id":"1qZXTQtmn86ZvRAsF1x28C0Of2fRErpcL","authorship_tag":"ABX9TyMEs0nGG3vkbmuUI6ojZJfU"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}